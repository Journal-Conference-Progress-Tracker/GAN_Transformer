{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整訓練集形狀: (10232, 14)\n",
      "測試集形狀: (2559, 14)\n",
      "          id        label                                          statement  \\\n",
      "0  7193.json         true  Northern Virginia is the most heavily traffick...   \n",
      "1  1608.json    half-true  The Democratic health care bill will \"collect ...   \n",
      "2  3844.json  mostly-true  Says for the first time ever, Texas lawmakers ...   \n",
      "3  1104.json    half-true  Only 15 percent of drug users are African-Amer...   \n",
      "4  3875.json  barely-true  Part of his ride was to warn the British that ...   \n",
      "\n",
      "                                subjects             speaker  \\\n",
      "0                         transportation       bob-mcdonnell   \n",
      "1                      health-care,taxes         todd-tiahrt   \n",
      "2  education,state-budget,state-finances         wendy-davis   \n",
      "3   crime,legal-issues,marijuana,pundits  arianna-huffington   \n",
      "4                        history,pundits         sarah-palin   \n",
      "\n",
      "                      job_title     state       party  barely_true  false  \\\n",
      "0                      Governor  Virginia  republican          6.0    5.0   \n",
      "1           U.S. Representative    Kansas  republican          0.0    0.0   \n",
      "2                 state senator     Texas    democrat          5.0    1.0   \n",
      "3  Founder, The Huffington Post       NaN        none          0.0    0.0   \n",
      "4                           NaN    Alaska  republican          9.0   19.0   \n",
      "\n",
      "   half_true  mostly_true  pants_on_fire  \\\n",
      "0        7.0          6.0            3.0   \n",
      "1        1.0          0.0            0.0   \n",
      "2        8.0         12.0            1.0   \n",
      "3        2.0          3.0            0.0   \n",
      "4        9.0          6.0            6.0   \n",
      "\n",
      "                                 context  \n",
      "0                     a news conference.  \n",
      "1           a speech on the House floor.  \n",
      "2                          a filibuster.  \n",
      "3   This Week with George Stephanopoulos  \n",
      "4                    an interview on Fox  \n",
      "           id        label                                          statement  \\\n",
      "0   7311.json        false  When George Bush became president of the Unite...   \n",
      "1   5497.json  mostly-true  A little less than 50 percent of the people in...   \n",
      "2   7580.json         true  On recusing herself from cases after receiving...   \n",
      "3   6985.json    half-true  Latin Americas economy is almost as big as the...   \n",
      "4  12222.json        false  Floridas regulations on the payday lending ind...   \n",
      "\n",
      "                                            subjects              speaker  \\\n",
      "0                        bush-administration,poverty         marcia-fudge   \n",
      "1  children,families,federal-budget,medicaid,medi...        rick-santorum   \n",
      "2                      campaign-finance,legal-issues  patience-roggensack   \n",
      "3                             economy,foreign-policy          mitt-romney   \n",
      "4  congress,financial-regulation,government-regul...       patrick-murphy   \n",
      "\n",
      "                                           job_title          state  \\\n",
      "0  Representative from Ohio's 11th Congressional ...           Ohio   \n",
      "1                                                NaN   Pennsylvania   \n",
      "2                    Wisconsin Supreme Court justice      Wisconsin   \n",
      "3                                    Former governor  Massachusetts   \n",
      "4                                                NaN        Florida   \n",
      "\n",
      "        party  barely_true  false  half_true  mostly_true  pants_on_fire  \\\n",
      "0    democrat          0.0    1.0        2.0          4.0            0.0   \n",
      "1  republican         12.0   16.0       13.0          7.0            5.0   \n",
      "2        none          0.0    0.0        0.0          1.0            0.0   \n",
      "3  republican         34.0   32.0       58.0         33.0           19.0   \n",
      "4    democrat          2.0    1.0        4.0          5.0            0.0   \n",
      "\n",
      "                                             context  \n",
      "0                      a panel discussion on poverty  \n",
      "1            a campaign speech in Steubenville, Ohio  \n",
      "2                                  a radio interview  \n",
      "3  the third presidential debate in Boca Raton, Fla.  \n",
      "4                   a conference call with reporters  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_train_full = pd.read_csv('train_full.tsv', sep='\\t')\n",
    "df_test_split = pd.read_csv('test_split.tsv', sep='\\t')\n",
    "print(\"完整訓練集形狀:\", df_train_full.shape)\n",
    "print(\"測試集形狀:\", df_test_split.shape)\n",
    "print(df_train_full.head())\n",
    "print(df_test_split.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_full = le.fit_transform(df_train_full['label'])\n",
    "y_test = le.transform(df_test_split['label'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "def tokenize(text):\n",
    "    # 簡易做法：以空白為分隔\n",
    "    return text.lower().split()\n",
    "\n",
    "# 建立詞彙表\n",
    "max_vocab_size = 10000\n",
    "all_tokens = []\n",
    "for text in df_train_full['statement']:\n",
    "    all_tokens.extend(tokenize(text))\n",
    "\n",
    "from collections import Counter\n",
    "counter = Counter(all_tokens)\n",
    "# 預留 2 個位置給 <PAD> 和 <UNK>\n",
    "most_common = counter.most_common(max_vocab_size - 2)\n",
    "vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "for word, freq in most_common:\n",
    "    vocab[word] = len(vocab)\n",
    "vocab_size = len(vocab)\n",
    "print(\"詞彙大小:\", vocab_size)\n",
    "\n",
    "max_length = 50\n",
    "\n",
    "def text_to_ids(text, vocab, max_length=50):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "    if len(ids) < max_length:\n",
    "        ids = ids + [vocab['<PAD>']] * (max_length - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_length]\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiarDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_length, label_encoder):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        self.label_encoder = label_encoder\n",
    "        self.texts = df['statement'].values\n",
    "        self.labels = label_encoder.transform(df['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        input_ids = torch.tensor(text_to_ids(text, self.vocab, self.max_length), dtype=torch.long)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return input_ids, label\n",
    "\n",
    "def create_dataloader(df, vocab, max_length, label_encoder, batch_size, shuffle=True):\n",
    "    dataset = LiarDataset(df, vocab, max_length, label_encoder)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, dropout=0.5):\n",
    "        super(EmbeddingDNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        # 平均池化 (mean pooling) -> (batch_size, embed_dim)\n",
    "        pooled = embedded.mean(dim=1)\n",
    "        \n",
    "        # 全連接層\n",
    "        out = self.dropout(pooled)\n",
    "        out = self.fc1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(df_train, df_test, embed_dim, hidden_dim, output_dim, dropout, num_epochs, batch_size, lr):\n",
    "    # 建立 DataLoader\n",
    "    train_loader = create_dataloader(df_train, vocab, max_length, le, batch_size, shuffle=True)\n",
    "    test_loader = create_dataloader(df_test, vocab, max_length, le, batch_size, shuffle=False)\n",
    "    \n",
    "    model = EmbeddingDNN(vocab_size, embed_dim, hidden_dim, output_dim, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 紀錄訓練過程\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # --- Testing ---\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "        \n",
    "        test_loss = test_running_loss / test_total\n",
    "        test_acc = test_correct / test_total\n",
    "        \n",
    "        epoch_list.append(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f} | \"\n",
    "              f\"Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    \n",
    "    return model, epoch_list, train_losses, test_losses, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整訓練集形狀: (10232, 14)\n",
      "測試集形狀: (2559, 14)\n",
      "詞彙大小: 10000\n",
      "\n",
      "=== 比例 1.0 (約 10232 筆資料) ===\n",
      "Epoch 1: Train Loss=1.7945, Train Acc=0.1642 | Test Loss=1.7896, Test Acc=0.1649\n",
      "Epoch 2: Train Loss=1.7908, Train Acc=0.1716 | Test Loss=1.7864, Test Acc=0.1719\n",
      "Epoch 3: Train Loss=1.7871, Train Acc=0.1825 | Test Loss=1.7836, Test Acc=0.1872\n",
      "Epoch 4: Train Loss=1.7839, Train Acc=0.1877 | Test Loss=1.7812, Test Acc=0.1977\n",
      "Epoch 5: Train Loss=1.7808, Train Acc=0.1977 | Test Loss=1.7789, Test Acc=0.2032\n",
      "Epoch 6: Train Loss=1.7794, Train Acc=0.1931 | Test Loss=1.7768, Test Acc=0.2040\n",
      "Epoch 7: Train Loss=1.7766, Train Acc=0.2018 | Test Loss=1.7747, Test Acc=0.2036\n",
      "Epoch 8: Train Loss=1.7743, Train Acc=0.2006 | Test Loss=1.7728, Test Acc=0.2044\n",
      "Epoch 9: Train Loss=1.7721, Train Acc=0.2039 | Test Loss=1.7710, Test Acc=0.2040\n",
      "Epoch 10: Train Loss=1.7699, Train Acc=0.2071 | Test Loss=1.7694, Test Acc=0.2036\n",
      "Epoch 11: Train Loss=1.7693, Train Acc=0.2059 | Test Loss=1.7678, Test Acc=0.2036\n",
      "Epoch 12: Train Loss=1.7676, Train Acc=0.2030 | Test Loss=1.7664, Test Acc=0.2036\n",
      "Epoch 13: Train Loss=1.7652, Train Acc=0.2080 | Test Loss=1.7651, Test Acc=0.2040\n",
      "Epoch 14: Train Loss=1.7640, Train Acc=0.2064 | Test Loss=1.7638, Test Acc=0.2032\n",
      "Epoch 15: Train Loss=1.7620, Train Acc=0.2106 | Test Loss=1.7627, Test Acc=0.2036\n",
      "Epoch 16: Train Loss=1.7624, Train Acc=0.2024 | Test Loss=1.7616, Test Acc=0.2032\n",
      "Epoch 17: Train Loss=1.7614, Train Acc=0.2027 | Test Loss=1.7607, Test Acc=0.2028\n",
      "Epoch 18: Train Loss=1.7605, Train Acc=0.2062 | Test Loss=1.7598, Test Acc=0.2024\n",
      "Epoch 19: Train Loss=1.7590, Train Acc=0.2096 | Test Loss=1.7590, Test Acc=0.2032\n",
      "Epoch 20: Train Loss=1.7590, Train Acc=0.2148 | Test Loss=1.7583, Test Acc=0.2036\n",
      "Epoch 21: Train Loss=1.7582, Train Acc=0.2070 | Test Loss=1.7576, Test Acc=0.2036\n",
      "Epoch 22: Train Loss=1.7570, Train Acc=0.2131 | Test Loss=1.7570, Test Acc=0.2040\n",
      "Epoch 23: Train Loss=1.7548, Train Acc=0.2139 | Test Loss=1.7564, Test Acc=0.2044\n",
      "Epoch 24: Train Loss=1.7562, Train Acc=0.2114 | Test Loss=1.7559, Test Acc=0.2036\n",
      "Epoch 25: Train Loss=1.7542, Train Acc=0.2176 | Test Loss=1.7555, Test Acc=0.2071\n",
      "Epoch 26: Train Loss=1.7549, Train Acc=0.2121 | Test Loss=1.7550, Test Acc=0.2091\n",
      "Epoch 27: Train Loss=1.7529, Train Acc=0.2140 | Test Loss=1.7545, Test Acc=0.2102\n",
      "Epoch 28: Train Loss=1.7528, Train Acc=0.2173 | Test Loss=1.7541, Test Acc=0.2138\n",
      "Epoch 29: Train Loss=1.7529, Train Acc=0.2132 | Test Loss=1.7536, Test Acc=0.2157\n",
      "Epoch 30: Train Loss=1.7517, Train Acc=0.2134 | Test Loss=1.7532, Test Acc=0.2157\n",
      "Epoch 31: Train Loss=1.7523, Train Acc=0.2183 | Test Loss=1.7528, Test Acc=0.2196\n",
      "Epoch 32: Train Loss=1.7519, Train Acc=0.2182 | Test Loss=1.7524, Test Acc=0.2216\n",
      "Epoch 33: Train Loss=1.7512, Train Acc=0.2132 | Test Loss=1.7520, Test Acc=0.2181\n",
      "Epoch 34: Train Loss=1.7501, Train Acc=0.2227 | Test Loss=1.7516, Test Acc=0.2200\n",
      "Epoch 35: Train Loss=1.7500, Train Acc=0.2228 | Test Loss=1.7511, Test Acc=0.2200\n",
      "Epoch 36: Train Loss=1.7488, Train Acc=0.2221 | Test Loss=1.7506, Test Acc=0.2224\n",
      "Epoch 37: Train Loss=1.7490, Train Acc=0.2221 | Test Loss=1.7501, Test Acc=0.2263\n",
      "Epoch 38: Train Loss=1.7478, Train Acc=0.2281 | Test Loss=1.7496, Test Acc=0.2267\n",
      "Epoch 39: Train Loss=1.7488, Train Acc=0.2191 | Test Loss=1.7492, Test Acc=0.2255\n",
      "Epoch 40: Train Loss=1.7473, Train Acc=0.2204 | Test Loss=1.7488, Test Acc=0.2224\n",
      "Epoch 41: Train Loss=1.7465, Train Acc=0.2241 | Test Loss=1.7484, Test Acc=0.2212\n",
      "Epoch 42: Train Loss=1.7461, Train Acc=0.2226 | Test Loss=1.7480, Test Acc=0.2200\n",
      "Epoch 43: Train Loss=1.7459, Train Acc=0.2222 | Test Loss=1.7476, Test Acc=0.2157\n",
      "Epoch 44: Train Loss=1.7441, Train Acc=0.2236 | Test Loss=1.7472, Test Acc=0.2157\n",
      "Epoch 45: Train Loss=1.7456, Train Acc=0.2146 | Test Loss=1.7468, Test Acc=0.2134\n",
      "Epoch 46: Train Loss=1.7450, Train Acc=0.2210 | Test Loss=1.7464, Test Acc=0.2149\n",
      "Epoch 47: Train Loss=1.7436, Train Acc=0.2260 | Test Loss=1.7461, Test Acc=0.2157\n",
      "Epoch 48: Train Loss=1.7443, Train Acc=0.2253 | Test Loss=1.7457, Test Acc=0.2173\n",
      "Epoch 49: Train Loss=1.7426, Train Acc=0.2252 | Test Loss=1.7454, Test Acc=0.2177\n",
      "Epoch 50: Train Loss=1.7429, Train Acc=0.2232 | Test Loss=1.7450, Test Acc=0.2161\n",
      "Epoch 51: Train Loss=1.7436, Train Acc=0.2225 | Test Loss=1.7447, Test Acc=0.2188\n",
      "Epoch 52: Train Loss=1.7426, Train Acc=0.2261 | Test Loss=1.7443, Test Acc=0.2196\n",
      "Epoch 53: Train Loss=1.7423, Train Acc=0.2295 | Test Loss=1.7440, Test Acc=0.2204\n",
      "Epoch 54: Train Loss=1.7401, Train Acc=0.2254 | Test Loss=1.7436, Test Acc=0.2259\n",
      "Epoch 55: Train Loss=1.7412, Train Acc=0.2352 | Test Loss=1.7432, Test Acc=0.2302\n",
      "Epoch 56: Train Loss=1.7407, Train Acc=0.2318 | Test Loss=1.7429, Test Acc=0.2360\n",
      "Epoch 57: Train Loss=1.7387, Train Acc=0.2334 | Test Loss=1.7425, Test Acc=0.2321\n",
      "Epoch 58: Train Loss=1.7380, Train Acc=0.2338 | Test Loss=1.7422, Test Acc=0.2368\n",
      "Epoch 59: Train Loss=1.7383, Train Acc=0.2367 | Test Loss=1.7418, Test Acc=0.2345\n",
      "Epoch 60: Train Loss=1.7390, Train Acc=0.2334 | Test Loss=1.7415, Test Acc=0.2337\n",
      "Epoch 61: Train Loss=1.7374, Train Acc=0.2380 | Test Loss=1.7412, Test Acc=0.2309\n",
      "Epoch 62: Train Loss=1.7359, Train Acc=0.2440 | Test Loss=1.7408, Test Acc=0.2321\n",
      "Epoch 63: Train Loss=1.7384, Train Acc=0.2390 | Test Loss=1.7405, Test Acc=0.2306\n",
      "Epoch 64: Train Loss=1.7354, Train Acc=0.2438 | Test Loss=1.7401, Test Acc=0.2317\n",
      "Epoch 65: Train Loss=1.7345, Train Acc=0.2436 | Test Loss=1.7397, Test Acc=0.2294\n",
      "Epoch 66: Train Loss=1.7353, Train Acc=0.2388 | Test Loss=1.7394, Test Acc=0.2306\n",
      "Epoch 67: Train Loss=1.7339, Train Acc=0.2441 | Test Loss=1.7391, Test Acc=0.2321\n",
      "Epoch 68: Train Loss=1.7354, Train Acc=0.2373 | Test Loss=1.7387, Test Acc=0.2313\n",
      "Epoch 69: Train Loss=1.7323, Train Acc=0.2454 | Test Loss=1.7382, Test Acc=0.2360\n",
      "Epoch 70: Train Loss=1.7358, Train Acc=0.2411 | Test Loss=1.7378, Test Acc=0.2360\n",
      "Epoch 71: Train Loss=1.7310, Train Acc=0.2384 | Test Loss=1.7374, Test Acc=0.2345\n",
      "Epoch 72: Train Loss=1.7300, Train Acc=0.2474 | Test Loss=1.7370, Test Acc=0.2349\n",
      "Epoch 73: Train Loss=1.7319, Train Acc=0.2369 | Test Loss=1.7366, Test Acc=0.2341\n",
      "Epoch 74: Train Loss=1.7297, Train Acc=0.2435 | Test Loss=1.7362, Test Acc=0.2349\n",
      "Epoch 75: Train Loss=1.7292, Train Acc=0.2418 | Test Loss=1.7358, Test Acc=0.2341\n",
      "Epoch 76: Train Loss=1.7288, Train Acc=0.2467 | Test Loss=1.7354, Test Acc=0.2341\n",
      "Epoch 77: Train Loss=1.7282, Train Acc=0.2481 | Test Loss=1.7350, Test Acc=0.2341\n",
      "Epoch 78: Train Loss=1.7277, Train Acc=0.2432 | Test Loss=1.7346, Test Acc=0.2360\n",
      "Epoch 79: Train Loss=1.7263, Train Acc=0.2447 | Test Loss=1.7343, Test Acc=0.2360\n",
      "Epoch 80: Train Loss=1.7278, Train Acc=0.2425 | Test Loss=1.7340, Test Acc=0.2333\n",
      "Epoch 81: Train Loss=1.7256, Train Acc=0.2473 | Test Loss=1.7337, Test Acc=0.2341\n",
      "Epoch 82: Train Loss=1.7266, Train Acc=0.2435 | Test Loss=1.7334, Test Acc=0.2352\n",
      "Epoch 83: Train Loss=1.7235, Train Acc=0.2494 | Test Loss=1.7332, Test Acc=0.2407\n",
      "Epoch 84: Train Loss=1.7241, Train Acc=0.2531 | Test Loss=1.7329, Test Acc=0.2395\n",
      "Epoch 85: Train Loss=1.7233, Train Acc=0.2521 | Test Loss=1.7327, Test Acc=0.2407\n",
      "Epoch 86: Train Loss=1.7252, Train Acc=0.2513 | Test Loss=1.7324, Test Acc=0.2399\n",
      "Epoch 87: Train Loss=1.7204, Train Acc=0.2525 | Test Loss=1.7322, Test Acc=0.2427\n",
      "Epoch 88: Train Loss=1.7215, Train Acc=0.2517 | Test Loss=1.7318, Test Acc=0.2423\n",
      "Epoch 89: Train Loss=1.7224, Train Acc=0.2440 | Test Loss=1.7315, Test Acc=0.2423\n",
      "Epoch 90: Train Loss=1.7200, Train Acc=0.2525 | Test Loss=1.7313, Test Acc=0.2423\n",
      "Epoch 91: Train Loss=1.7179, Train Acc=0.2581 | Test Loss=1.7310, Test Acc=0.2411\n",
      "Epoch 92: Train Loss=1.7190, Train Acc=0.2522 | Test Loss=1.7307, Test Acc=0.2419\n",
      "Epoch 93: Train Loss=1.7202, Train Acc=0.2470 | Test Loss=1.7305, Test Acc=0.2446\n",
      "Epoch 94: Train Loss=1.7193, Train Acc=0.2503 | Test Loss=1.7303, Test Acc=0.2435\n",
      "Epoch 95: Train Loss=1.7177, Train Acc=0.2546 | Test Loss=1.7300, Test Acc=0.2450\n",
      "Epoch 96: Train Loss=1.7178, Train Acc=0.2511 | Test Loss=1.7296, Test Acc=0.2470\n",
      "Epoch 97: Train Loss=1.7166, Train Acc=0.2558 | Test Loss=1.7291, Test Acc=0.2462\n",
      "Epoch 98: Train Loss=1.7140, Train Acc=0.2608 | Test Loss=1.7286, Test Acc=0.2485\n",
      "Epoch 99: Train Loss=1.7133, Train Acc=0.2622 | Test Loss=1.7281, Test Acc=0.2485\n",
      "Epoch 100: Train Loss=1.7151, Train Acc=0.2527 | Test Loss=1.7276, Test Acc=0.2478\n",
      "分類報告 (Train Subset 100%):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.05      0.09       421\n",
      "       false       0.24      0.52      0.33       501\n",
      "   half-true       0.24      0.41      0.30       526\n",
      " mostly-true       0.27      0.26      0.26       491\n",
      "  pants-fire       0.00      0.00      0.00       209\n",
      "        true       0.35      0.02      0.04       411\n",
      "\n",
      "    accuracy                           0.25      2559\n",
      "   macro avg       0.22      0.21      0.17      2559\n",
      "weighted avg       0.24      0.25      0.20      2559\n",
      "\n",
      "\n",
      "=== 比例 0.5 (約 5116 筆資料) ===\n",
      "Epoch 1: Train Loss=1.7956, Train Acc=0.1650 | Test Loss=1.7922, Test Acc=0.1981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=1.7932, Train Acc=0.1789 | Test Loss=1.7904, Test Acc=0.1938\n",
      "Epoch 3: Train Loss=1.7904, Train Acc=0.1826 | Test Loss=1.7886, Test Acc=0.1946\n",
      "Epoch 4: Train Loss=1.7896, Train Acc=0.1918 | Test Loss=1.7869, Test Acc=0.1954\n",
      "Epoch 5: Train Loss=1.7872, Train Acc=0.1964 | Test Loss=1.7852, Test Acc=0.1938\n",
      "Epoch 6: Train Loss=1.7863, Train Acc=0.1935 | Test Loss=1.7837, Test Acc=0.1930\n",
      "Epoch 7: Train Loss=1.7839, Train Acc=0.1970 | Test Loss=1.7822, Test Acc=0.1915\n",
      "Epoch 8: Train Loss=1.7821, Train Acc=0.2088 | Test Loss=1.7807, Test Acc=0.1927\n",
      "Epoch 9: Train Loss=1.7808, Train Acc=0.1962 | Test Loss=1.7792, Test Acc=0.1946\n",
      "Epoch 10: Train Loss=1.7785, Train Acc=0.1984 | Test Loss=1.7778, Test Acc=0.1993\n",
      "Epoch 11: Train Loss=1.7770, Train Acc=0.2002 | Test Loss=1.7765, Test Acc=0.1989\n",
      "Epoch 12: Train Loss=1.7757, Train Acc=0.2035 | Test Loss=1.7752, Test Acc=0.1973\n",
      "Epoch 13: Train Loss=1.7743, Train Acc=0.2084 | Test Loss=1.7739, Test Acc=0.1989\n",
      "Epoch 14: Train Loss=1.7720, Train Acc=0.2091 | Test Loss=1.7726, Test Acc=0.2001\n",
      "Epoch 15: Train Loss=1.7711, Train Acc=0.2037 | Test Loss=1.7714, Test Acc=0.2040\n",
      "Epoch 16: Train Loss=1.7701, Train Acc=0.2025 | Test Loss=1.7702, Test Acc=0.2009\n",
      "Epoch 17: Train Loss=1.7700, Train Acc=0.2017 | Test Loss=1.7691, Test Acc=0.2020\n",
      "Epoch 18: Train Loss=1.7663, Train Acc=0.2013 | Test Loss=1.7680, Test Acc=0.2063\n",
      "Epoch 19: Train Loss=1.7669, Train Acc=0.2041 | Test Loss=1.7669, Test Acc=0.2048\n",
      "Epoch 20: Train Loss=1.7647, Train Acc=0.2095 | Test Loss=1.7659, Test Acc=0.2071\n",
      "Epoch 21: Train Loss=1.7631, Train Acc=0.2047 | Test Loss=1.7649, Test Acc=0.2036\n",
      "Epoch 22: Train Loss=1.7615, Train Acc=0.2076 | Test Loss=1.7639, Test Acc=0.2055\n",
      "Epoch 23: Train Loss=1.7614, Train Acc=0.2080 | Test Loss=1.7630, Test Acc=0.2114\n",
      "Epoch 24: Train Loss=1.7600, Train Acc=0.2177 | Test Loss=1.7621, Test Acc=0.2118\n",
      "Epoch 25: Train Loss=1.7588, Train Acc=0.2129 | Test Loss=1.7612, Test Acc=0.2098\n",
      "Epoch 26: Train Loss=1.7582, Train Acc=0.2168 | Test Loss=1.7604, Test Acc=0.2134\n",
      "Epoch 27: Train Loss=1.7563, Train Acc=0.2097 | Test Loss=1.7596, Test Acc=0.2181\n",
      "Epoch 28: Train Loss=1.7560, Train Acc=0.2185 | Test Loss=1.7588, Test Acc=0.2169\n",
      "Epoch 29: Train Loss=1.7549, Train Acc=0.2158 | Test Loss=1.7581, Test Acc=0.2157\n",
      "Epoch 30: Train Loss=1.7531, Train Acc=0.2197 | Test Loss=1.7573, Test Acc=0.2141\n",
      "Epoch 31: Train Loss=1.7524, Train Acc=0.2306 | Test Loss=1.7566, Test Acc=0.2134\n",
      "Epoch 32: Train Loss=1.7499, Train Acc=0.2197 | Test Loss=1.7559, Test Acc=0.2134\n",
      "Epoch 33: Train Loss=1.7499, Train Acc=0.2308 | Test Loss=1.7552, Test Acc=0.2165\n",
      "Epoch 34: Train Loss=1.7506, Train Acc=0.2295 | Test Loss=1.7546, Test Acc=0.2169\n",
      "Epoch 35: Train Loss=1.7491, Train Acc=0.2219 | Test Loss=1.7539, Test Acc=0.2169\n",
      "Epoch 36: Train Loss=1.7471, Train Acc=0.2322 | Test Loss=1.7533, Test Acc=0.2192\n",
      "Epoch 37: Train Loss=1.7478, Train Acc=0.2248 | Test Loss=1.7526, Test Acc=0.2208\n",
      "Epoch 38: Train Loss=1.7472, Train Acc=0.2308 | Test Loss=1.7520, Test Acc=0.2263\n",
      "Epoch 39: Train Loss=1.7468, Train Acc=0.2299 | Test Loss=1.7514, Test Acc=0.2302\n",
      "Epoch 40: Train Loss=1.7438, Train Acc=0.2299 | Test Loss=1.7507, Test Acc=0.2286\n",
      "Epoch 41: Train Loss=1.7435, Train Acc=0.2320 | Test Loss=1.7501, Test Acc=0.2356\n",
      "Epoch 42: Train Loss=1.7430, Train Acc=0.2244 | Test Loss=1.7495, Test Acc=0.2376\n",
      "Epoch 43: Train Loss=1.7427, Train Acc=0.2381 | Test Loss=1.7489, Test Acc=0.2372\n",
      "Epoch 44: Train Loss=1.7408, Train Acc=0.2340 | Test Loss=1.7483, Test Acc=0.2395\n",
      "Epoch 45: Train Loss=1.7406, Train Acc=0.2389 | Test Loss=1.7477, Test Acc=0.2419\n",
      "Epoch 46: Train Loss=1.7380, Train Acc=0.2502 | Test Loss=1.7471, Test Acc=0.2399\n",
      "Epoch 47: Train Loss=1.7396, Train Acc=0.2414 | Test Loss=1.7464, Test Acc=0.2427\n",
      "Epoch 48: Train Loss=1.7358, Train Acc=0.2416 | Test Loss=1.7458, Test Acc=0.2470\n",
      "Epoch 49: Train Loss=1.7354, Train Acc=0.2408 | Test Loss=1.7452, Test Acc=0.2442\n",
      "Epoch 50: Train Loss=1.7358, Train Acc=0.2383 | Test Loss=1.7446, Test Acc=0.2446\n",
      "Epoch 51: Train Loss=1.7345, Train Acc=0.2533 | Test Loss=1.7440, Test Acc=0.2470\n",
      "Epoch 52: Train Loss=1.7337, Train Acc=0.2414 | Test Loss=1.7434, Test Acc=0.2478\n",
      "Epoch 53: Train Loss=1.7328, Train Acc=0.2402 | Test Loss=1.7428, Test Acc=0.2454\n",
      "Epoch 54: Train Loss=1.7311, Train Acc=0.2508 | Test Loss=1.7422, Test Acc=0.2458\n",
      "Epoch 55: Train Loss=1.7284, Train Acc=0.2514 | Test Loss=1.7416, Test Acc=0.2458\n",
      "Epoch 56: Train Loss=1.7281, Train Acc=0.2496 | Test Loss=1.7410, Test Acc=0.2442\n",
      "Epoch 57: Train Loss=1.7266, Train Acc=0.2488 | Test Loss=1.7404, Test Acc=0.2431\n",
      "Epoch 58: Train Loss=1.7255, Train Acc=0.2543 | Test Loss=1.7398, Test Acc=0.2423\n",
      "Epoch 59: Train Loss=1.7237, Train Acc=0.2604 | Test Loss=1.7392, Test Acc=0.2423\n",
      "Epoch 60: Train Loss=1.7225, Train Acc=0.2641 | Test Loss=1.7387, Test Acc=0.2435\n",
      "Epoch 61: Train Loss=1.7223, Train Acc=0.2600 | Test Loss=1.7381, Test Acc=0.2435\n",
      "Epoch 62: Train Loss=1.7244, Train Acc=0.2520 | Test Loss=1.7376, Test Acc=0.2423\n",
      "Epoch 63: Train Loss=1.7199, Train Acc=0.2619 | Test Loss=1.7370, Test Acc=0.2431\n",
      "Epoch 64: Train Loss=1.7213, Train Acc=0.2643 | Test Loss=1.7365, Test Acc=0.2423\n",
      "Epoch 65: Train Loss=1.7156, Train Acc=0.2649 | Test Loss=1.7359, Test Acc=0.2407\n",
      "Epoch 66: Train Loss=1.7119, Train Acc=0.2694 | Test Loss=1.7354, Test Acc=0.2419\n",
      "Epoch 67: Train Loss=1.7101, Train Acc=0.2772 | Test Loss=1.7349, Test Acc=0.2431\n",
      "Epoch 68: Train Loss=1.7142, Train Acc=0.2666 | Test Loss=1.7344, Test Acc=0.2419\n",
      "Epoch 69: Train Loss=1.7135, Train Acc=0.2670 | Test Loss=1.7339, Test Acc=0.2438\n",
      "Epoch 70: Train Loss=1.7103, Train Acc=0.2746 | Test Loss=1.7335, Test Acc=0.2462\n",
      "Epoch 71: Train Loss=1.7046, Train Acc=0.2801 | Test Loss=1.7330, Test Acc=0.2450\n",
      "Epoch 72: Train Loss=1.7047, Train Acc=0.2682 | Test Loss=1.7325, Test Acc=0.2438\n",
      "Epoch 73: Train Loss=1.7043, Train Acc=0.2801 | Test Loss=1.7320, Test Acc=0.2438\n",
      "Epoch 74: Train Loss=1.6999, Train Acc=0.2768 | Test Loss=1.7315, Test Acc=0.2431\n",
      "Epoch 75: Train Loss=1.7007, Train Acc=0.2791 | Test Loss=1.7311, Test Acc=0.2442\n",
      "Epoch 76: Train Loss=1.6972, Train Acc=0.2781 | Test Loss=1.7306, Test Acc=0.2423\n",
      "Epoch 77: Train Loss=1.6966, Train Acc=0.2844 | Test Loss=1.7302, Test Acc=0.2399\n",
      "Epoch 78: Train Loss=1.6922, Train Acc=0.2823 | Test Loss=1.7298, Test Acc=0.2411\n",
      "Epoch 79: Train Loss=1.6926, Train Acc=0.2862 | Test Loss=1.7295, Test Acc=0.2403\n",
      "Epoch 80: Train Loss=1.6898, Train Acc=0.2899 | Test Loss=1.7291, Test Acc=0.2399\n",
      "Epoch 81: Train Loss=1.6906, Train Acc=0.2848 | Test Loss=1.7288, Test Acc=0.2403\n",
      "Epoch 82: Train Loss=1.6879, Train Acc=0.2895 | Test Loss=1.7284, Test Acc=0.2399\n",
      "Epoch 83: Train Loss=1.6853, Train Acc=0.2932 | Test Loss=1.7281, Test Acc=0.2399\n",
      "Epoch 84: Train Loss=1.6821, Train Acc=0.2983 | Test Loss=1.7278, Test Acc=0.2411\n",
      "Epoch 85: Train Loss=1.6798, Train Acc=0.3000 | Test Loss=1.7275, Test Acc=0.2419\n",
      "Epoch 86: Train Loss=1.6814, Train Acc=0.2965 | Test Loss=1.7273, Test Acc=0.2431\n",
      "Epoch 87: Train Loss=1.6785, Train Acc=0.2932 | Test Loss=1.7271, Test Acc=0.2419\n",
      "Epoch 88: Train Loss=1.6788, Train Acc=0.2920 | Test Loss=1.7269, Test Acc=0.2427\n",
      "Epoch 89: Train Loss=1.6735, Train Acc=0.2942 | Test Loss=1.7268, Test Acc=0.2423\n",
      "Epoch 90: Train Loss=1.6688, Train Acc=0.3028 | Test Loss=1.7267, Test Acc=0.2431\n",
      "Epoch 91: Train Loss=1.6707, Train Acc=0.3051 | Test Loss=1.7266, Test Acc=0.2431\n",
      "Epoch 92: Train Loss=1.6630, Train Acc=0.3016 | Test Loss=1.7265, Test Acc=0.2431\n",
      "Epoch 93: Train Loss=1.6675, Train Acc=0.3032 | Test Loss=1.7265, Test Acc=0.2438\n",
      "Epoch 94: Train Loss=1.6634, Train Acc=0.3116 | Test Loss=1.7265, Test Acc=0.2419\n",
      "Epoch 95: Train Loss=1.6574, Train Acc=0.3139 | Test Loss=1.7265, Test Acc=0.2403\n",
      "Epoch 96: Train Loss=1.6588, Train Acc=0.3049 | Test Loss=1.7266, Test Acc=0.2407\n",
      "Epoch 97: Train Loss=1.6540, Train Acc=0.3174 | Test Loss=1.7266, Test Acc=0.2399\n",
      "Epoch 98: Train Loss=1.6523, Train Acc=0.3116 | Test Loss=1.7267, Test Acc=0.2395\n",
      "Epoch 99: Train Loss=1.6510, Train Acc=0.3104 | Test Loss=1.7268, Test Acc=0.2399\n",
      "Epoch 100: Train Loss=1.6492, Train Acc=0.3196 | Test Loss=1.7270, Test Acc=0.2407\n",
      "分類報告 (Train Subset 50%):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.10      0.14       421\n",
      "       false       0.25      0.50      0.34       501\n",
      "   half-true       0.23      0.33      0.27       526\n",
      " mostly-true       0.26      0.23      0.24       491\n",
      "  pants-fire       0.00      0.00      0.00       209\n",
      "        true       0.19      0.08      0.11       411\n",
      "\n",
      "    accuracy                           0.24      2559\n",
      "   macro avg       0.19      0.21      0.18      2559\n",
      "weighted avg       0.21      0.24      0.21      2559\n",
      "\n",
      "\n",
      "=== 比例 0.25 (約 2558 筆資料) ===\n",
      "Epoch 1: Train Loss=1.8056, Train Acc=0.0934 | Test Loss=1.8014, Test Acc=0.0809\n",
      "Epoch 2: Train Loss=1.8022, Train Acc=0.1009 | Test Loss=1.7990, Test Acc=0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=1.8003, Train Acc=0.1118 | Test Loss=1.7967, Test Acc=0.1032\n",
      "Epoch 4: Train Loss=1.7953, Train Acc=0.1286 | Test Loss=1.7945, Test Acc=0.1204\n",
      "Epoch 5: Train Loss=1.7943, Train Acc=0.1403 | Test Loss=1.7923, Test Acc=0.1391\n",
      "Epoch 6: Train Loss=1.7911, Train Acc=0.1673 | Test Loss=1.7902, Test Acc=0.1719\n",
      "Epoch 7: Train Loss=1.7900, Train Acc=0.1673 | Test Loss=1.7882, Test Acc=0.1899\n",
      "Epoch 8: Train Loss=1.7869, Train Acc=0.1884 | Test Loss=1.7862, Test Acc=0.2005\n",
      "Epoch 9: Train Loss=1.7844, Train Acc=0.2029 | Test Loss=1.7843, Test Acc=0.2036\n",
      "Epoch 10: Train Loss=1.7827, Train Acc=0.2142 | Test Loss=1.7824, Test Acc=0.2118\n",
      "Epoch 11: Train Loss=1.7810, Train Acc=0.2029 | Test Loss=1.7805, Test Acc=0.2122\n",
      "Epoch 12: Train Loss=1.7777, Train Acc=0.2142 | Test Loss=1.7787, Test Acc=0.2145\n",
      "Epoch 13: Train Loss=1.7759, Train Acc=0.2217 | Test Loss=1.7769, Test Acc=0.2138\n",
      "Epoch 14: Train Loss=1.7724, Train Acc=0.2260 | Test Loss=1.7752, Test Acc=0.2153\n",
      "Epoch 15: Train Loss=1.7708, Train Acc=0.2158 | Test Loss=1.7735, Test Acc=0.2173\n",
      "Epoch 16: Train Loss=1.7687, Train Acc=0.2189 | Test Loss=1.7719, Test Acc=0.2165\n",
      "Epoch 17: Train Loss=1.7671, Train Acc=0.2275 | Test Loss=1.7703, Test Acc=0.2169\n",
      "Epoch 18: Train Loss=1.7644, Train Acc=0.2330 | Test Loss=1.7687, Test Acc=0.2165\n",
      "Epoch 19: Train Loss=1.7642, Train Acc=0.2232 | Test Loss=1.7672, Test Acc=0.2181\n",
      "Epoch 20: Train Loss=1.7629, Train Acc=0.2260 | Test Loss=1.7658, Test Acc=0.2192\n",
      "Epoch 21: Train Loss=1.7611, Train Acc=0.2310 | Test Loss=1.7645, Test Acc=0.2184\n",
      "Epoch 22: Train Loss=1.7579, Train Acc=0.2197 | Test Loss=1.7632, Test Acc=0.2204\n",
      "Epoch 23: Train Loss=1.7581, Train Acc=0.2248 | Test Loss=1.7619, Test Acc=0.2216\n",
      "Epoch 24: Train Loss=1.7542, Train Acc=0.2228 | Test Loss=1.7608, Test Acc=0.2231\n",
      "Epoch 25: Train Loss=1.7549, Train Acc=0.2400 | Test Loss=1.7597, Test Acc=0.2235\n",
      "Epoch 26: Train Loss=1.7510, Train Acc=0.2310 | Test Loss=1.7586, Test Acc=0.2251\n",
      "Epoch 27: Train Loss=1.7496, Train Acc=0.2373 | Test Loss=1.7577, Test Acc=0.2255\n",
      "Epoch 28: Train Loss=1.7487, Train Acc=0.2310 | Test Loss=1.7568, Test Acc=0.2267\n",
      "Epoch 29: Train Loss=1.7484, Train Acc=0.2263 | Test Loss=1.7559, Test Acc=0.2263\n",
      "Epoch 30: Train Loss=1.7479, Train Acc=0.2377 | Test Loss=1.7551, Test Acc=0.2243\n",
      "Epoch 31: Train Loss=1.7446, Train Acc=0.2424 | Test Loss=1.7544, Test Acc=0.2274\n",
      "Epoch 32: Train Loss=1.7436, Train Acc=0.2428 | Test Loss=1.7537, Test Acc=0.2267\n",
      "Epoch 33: Train Loss=1.7453, Train Acc=0.2338 | Test Loss=1.7531, Test Acc=0.2267\n",
      "Epoch 34: Train Loss=1.7419, Train Acc=0.2459 | Test Loss=1.7525, Test Acc=0.2270\n",
      "Epoch 35: Train Loss=1.7373, Train Acc=0.2463 | Test Loss=1.7520, Test Acc=0.2286\n",
      "Epoch 36: Train Loss=1.7391, Train Acc=0.2357 | Test Loss=1.7515, Test Acc=0.2317\n",
      "Epoch 37: Train Loss=1.7391, Train Acc=0.2439 | Test Loss=1.7509, Test Acc=0.2337\n",
      "Epoch 38: Train Loss=1.7351, Train Acc=0.2494 | Test Loss=1.7505, Test Acc=0.2321\n",
      "Epoch 39: Train Loss=1.7344, Train Acc=0.2459 | Test Loss=1.7500, Test Acc=0.2349\n",
      "Epoch 40: Train Loss=1.7338, Train Acc=0.2510 | Test Loss=1.7495, Test Acc=0.2352\n",
      "Epoch 41: Train Loss=1.7330, Train Acc=0.2482 | Test Loss=1.7491, Test Acc=0.2325\n",
      "Epoch 42: Train Loss=1.7262, Train Acc=0.2721 | Test Loss=1.7487, Test Acc=0.2333\n",
      "Epoch 43: Train Loss=1.7332, Train Acc=0.2553 | Test Loss=1.7483, Test Acc=0.2317\n",
      "Epoch 44: Train Loss=1.7306, Train Acc=0.2635 | Test Loss=1.7478, Test Acc=0.2309\n",
      "Epoch 45: Train Loss=1.7284, Train Acc=0.2674 | Test Loss=1.7475, Test Acc=0.2325\n",
      "Epoch 46: Train Loss=1.7241, Train Acc=0.2725 | Test Loss=1.7471, Test Acc=0.2325\n",
      "Epoch 47: Train Loss=1.7265, Train Acc=0.2623 | Test Loss=1.7467, Test Acc=0.2313\n",
      "Epoch 48: Train Loss=1.7213, Train Acc=0.2764 | Test Loss=1.7463, Test Acc=0.2302\n",
      "Epoch 49: Train Loss=1.7270, Train Acc=0.2443 | Test Loss=1.7459, Test Acc=0.2309\n",
      "Epoch 50: Train Loss=1.7182, Train Acc=0.2729 | Test Loss=1.7455, Test Acc=0.2302\n",
      "Epoch 51: Train Loss=1.7209, Train Acc=0.2623 | Test Loss=1.7451, Test Acc=0.2302\n",
      "Epoch 52: Train Loss=1.7174, Train Acc=0.2756 | Test Loss=1.7447, Test Acc=0.2306\n",
      "Epoch 53: Train Loss=1.7143, Train Acc=0.2713 | Test Loss=1.7443, Test Acc=0.2302\n",
      "Epoch 54: Train Loss=1.7130, Train Acc=0.2697 | Test Loss=1.7438, Test Acc=0.2321\n",
      "Epoch 55: Train Loss=1.7095, Train Acc=0.2858 | Test Loss=1.7434, Test Acc=0.2337\n",
      "Epoch 56: Train Loss=1.7145, Train Acc=0.2815 | Test Loss=1.7430, Test Acc=0.2352\n",
      "Epoch 57: Train Loss=1.7095, Train Acc=0.2791 | Test Loss=1.7426, Test Acc=0.2368\n",
      "Epoch 58: Train Loss=1.7048, Train Acc=0.2866 | Test Loss=1.7422, Test Acc=0.2352\n",
      "Epoch 59: Train Loss=1.7039, Train Acc=0.2944 | Test Loss=1.7418, Test Acc=0.2352\n",
      "Epoch 60: Train Loss=1.7000, Train Acc=0.3010 | Test Loss=1.7414, Test Acc=0.2356\n",
      "Epoch 61: Train Loss=1.7031, Train Acc=0.2932 | Test Loss=1.7410, Test Acc=0.2356\n",
      "Epoch 62: Train Loss=1.7030, Train Acc=0.2803 | Test Loss=1.7406, Test Acc=0.2360\n",
      "Epoch 63: Train Loss=1.6955, Train Acc=0.2842 | Test Loss=1.7402, Test Acc=0.2360\n",
      "Epoch 64: Train Loss=1.6949, Train Acc=0.2885 | Test Loss=1.7399, Test Acc=0.2364\n",
      "Epoch 65: Train Loss=1.6957, Train Acc=0.2819 | Test Loss=1.7395, Test Acc=0.2349\n",
      "Epoch 66: Train Loss=1.6922, Train Acc=0.2916 | Test Loss=1.7392, Test Acc=0.2345\n",
      "Epoch 67: Train Loss=1.6870, Train Acc=0.2963 | Test Loss=1.7389, Test Acc=0.2349\n",
      "Epoch 68: Train Loss=1.6848, Train Acc=0.2963 | Test Loss=1.7385, Test Acc=0.2349\n",
      "Epoch 69: Train Loss=1.6866, Train Acc=0.2971 | Test Loss=1.7382, Test Acc=0.2345\n",
      "Epoch 70: Train Loss=1.6839, Train Acc=0.2998 | Test Loss=1.7379, Test Acc=0.2345\n",
      "Epoch 71: Train Loss=1.6794, Train Acc=0.3100 | Test Loss=1.7376, Test Acc=0.2337\n",
      "Epoch 72: Train Loss=1.6729, Train Acc=0.3018 | Test Loss=1.7373, Test Acc=0.2352\n",
      "Epoch 73: Train Loss=1.6732, Train Acc=0.3135 | Test Loss=1.7370, Test Acc=0.2337\n",
      "Epoch 74: Train Loss=1.6713, Train Acc=0.3167 | Test Loss=1.7368, Test Acc=0.2337\n",
      "Epoch 75: Train Loss=1.6708, Train Acc=0.3057 | Test Loss=1.7366, Test Acc=0.2352\n",
      "Epoch 76: Train Loss=1.6631, Train Acc=0.3131 | Test Loss=1.7364, Test Acc=0.2352\n",
      "Epoch 77: Train Loss=1.6640, Train Acc=0.3108 | Test Loss=1.7363, Test Acc=0.2360\n",
      "Epoch 78: Train Loss=1.6617, Train Acc=0.3155 | Test Loss=1.7362, Test Acc=0.2376\n",
      "Epoch 79: Train Loss=1.6606, Train Acc=0.3225 | Test Loss=1.7361, Test Acc=0.2356\n",
      "Epoch 80: Train Loss=1.6575, Train Acc=0.3186 | Test Loss=1.7361, Test Acc=0.2360\n",
      "Epoch 81: Train Loss=1.6481, Train Acc=0.3299 | Test Loss=1.7361, Test Acc=0.2360\n",
      "Epoch 82: Train Loss=1.6461, Train Acc=0.3296 | Test Loss=1.7361, Test Acc=0.2356\n",
      "Epoch 83: Train Loss=1.6473, Train Acc=0.3241 | Test Loss=1.7362, Test Acc=0.2364\n",
      "Epoch 84: Train Loss=1.6479, Train Acc=0.3268 | Test Loss=1.7362, Test Acc=0.2364\n",
      "Epoch 85: Train Loss=1.6395, Train Acc=0.3210 | Test Loss=1.7363, Test Acc=0.2349\n",
      "Epoch 86: Train Loss=1.6264, Train Acc=0.3432 | Test Loss=1.7365, Test Acc=0.2341\n",
      "Epoch 87: Train Loss=1.6277, Train Acc=0.3393 | Test Loss=1.7367, Test Acc=0.2352\n",
      "Epoch 88: Train Loss=1.6259, Train Acc=0.3366 | Test Loss=1.7369, Test Acc=0.2341\n",
      "Epoch 89: Train Loss=1.6307, Train Acc=0.3237 | Test Loss=1.7372, Test Acc=0.2372\n",
      "Epoch 90: Train Loss=1.6130, Train Acc=0.3550 | Test Loss=1.7374, Test Acc=0.2368\n",
      "Epoch 91: Train Loss=1.6134, Train Acc=0.3401 | Test Loss=1.7378, Test Acc=0.2368\n",
      "Epoch 92: Train Loss=1.6110, Train Acc=0.3616 | Test Loss=1.7382, Test Acc=0.2376\n",
      "Epoch 93: Train Loss=1.6127, Train Acc=0.3370 | Test Loss=1.7386, Test Acc=0.2368\n",
      "Epoch 94: Train Loss=1.5980, Train Acc=0.3624 | Test Loss=1.7391, Test Acc=0.2364\n",
      "Epoch 95: Train Loss=1.6009, Train Acc=0.3526 | Test Loss=1.7396, Test Acc=0.2380\n",
      "Epoch 96: Train Loss=1.5924, Train Acc=0.3608 | Test Loss=1.7402, Test Acc=0.2380\n",
      "Epoch 97: Train Loss=1.5949, Train Acc=0.3464 | Test Loss=1.7408, Test Acc=0.2392\n",
      "Epoch 98: Train Loss=1.5913, Train Acc=0.3526 | Test Loss=1.7415, Test Acc=0.2380\n",
      "Epoch 99: Train Loss=1.5823, Train Acc=0.3663 | Test Loss=1.7422, Test Acc=0.2376\n",
      "Epoch 100: Train Loss=1.5790, Train Acc=0.3729 | Test Loss=1.7429, Test Acc=0.2384\n",
      "分類報告 (Train Subset 25%):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.23      0.09      0.12       421\n",
      "       false       0.25      0.47      0.33       501\n",
      "   half-true       0.24      0.37      0.29       526\n",
      " mostly-true       0.24      0.21      0.23       491\n",
      "  pants-fire       0.00      0.00      0.00       209\n",
      "        true       0.17      0.09      0.12       411\n",
      "\n",
      "    accuracy                           0.24      2559\n",
      "   macro avg       0.19      0.21      0.18      2559\n",
      "weighted avg       0.21      0.24      0.21      2559\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 比例 0.1 (約 1023 筆資料) ===\n",
      "Epoch 1: Train Loss=1.7937, Train Acc=0.1916 | Test Loss=1.7899, Test Acc=0.1973\n",
      "Epoch 2: Train Loss=1.7909, Train Acc=0.1906 | Test Loss=1.7884, Test Acc=0.1981\n",
      "Epoch 3: Train Loss=1.7892, Train Acc=0.1926 | Test Loss=1.7869, Test Acc=0.2009\n",
      "Epoch 4: Train Loss=1.7860, Train Acc=0.2004 | Test Loss=1.7854, Test Acc=0.1997\n",
      "Epoch 5: Train Loss=1.7830, Train Acc=0.2111 | Test Loss=1.7840, Test Acc=0.1989\n",
      "Epoch 6: Train Loss=1.7793, Train Acc=0.2297 | Test Loss=1.7826, Test Acc=0.1993\n",
      "Epoch 7: Train Loss=1.7795, Train Acc=0.2170 | Test Loss=1.7813, Test Acc=0.1985\n",
      "Epoch 8: Train Loss=1.7766, Train Acc=0.2209 | Test Loss=1.7800, Test Acc=0.1989\n",
      "Epoch 9: Train Loss=1.7742, Train Acc=0.2072 | Test Loss=1.7787, Test Acc=0.1970\n",
      "Epoch 10: Train Loss=1.7730, Train Acc=0.2082 | Test Loss=1.7774, Test Acc=0.2001\n",
      "Epoch 11: Train Loss=1.7717, Train Acc=0.2170 | Test Loss=1.7762, Test Acc=0.1977\n",
      "Epoch 12: Train Loss=1.7711, Train Acc=0.2268 | Test Loss=1.7750, Test Acc=0.1962\n",
      "Epoch 13: Train Loss=1.7659, Train Acc=0.2297 | Test Loss=1.7738, Test Acc=0.1977\n",
      "Epoch 14: Train Loss=1.7673, Train Acc=0.2209 | Test Loss=1.7727, Test Acc=0.1985\n",
      "Epoch 15: Train Loss=1.7628, Train Acc=0.2395 | Test Loss=1.7716, Test Acc=0.1966\n",
      "Epoch 16: Train Loss=1.7625, Train Acc=0.2395 | Test Loss=1.7705, Test Acc=0.1958\n",
      "Epoch 17: Train Loss=1.7597, Train Acc=0.2385 | Test Loss=1.7695, Test Acc=0.1962\n",
      "Epoch 18: Train Loss=1.7568, Train Acc=0.2473 | Test Loss=1.7685, Test Acc=0.1927\n",
      "Epoch 19: Train Loss=1.7568, Train Acc=0.2463 | Test Loss=1.7676, Test Acc=0.1970\n",
      "Epoch 20: Train Loss=1.7525, Train Acc=0.2463 | Test Loss=1.7667, Test Acc=0.1985\n",
      "Epoch 21: Train Loss=1.7527, Train Acc=0.2512 | Test Loss=1.7658, Test Acc=0.2016\n",
      "Epoch 22: Train Loss=1.7521, Train Acc=0.2542 | Test Loss=1.7650, Test Acc=0.2005\n",
      "Epoch 23: Train Loss=1.7474, Train Acc=0.2620 | Test Loss=1.7643, Test Acc=0.2013\n",
      "Epoch 24: Train Loss=1.7482, Train Acc=0.2659 | Test Loss=1.7635, Test Acc=0.2024\n",
      "Epoch 25: Train Loss=1.7484, Train Acc=0.2395 | Test Loss=1.7629, Test Acc=0.2024\n",
      "Epoch 26: Train Loss=1.7436, Train Acc=0.2493 | Test Loss=1.7622, Test Acc=0.2020\n",
      "Epoch 27: Train Loss=1.7424, Train Acc=0.2688 | Test Loss=1.7617, Test Acc=0.2013\n",
      "Epoch 28: Train Loss=1.7421, Train Acc=0.2590 | Test Loss=1.7612, Test Acc=0.2036\n",
      "Epoch 29: Train Loss=1.7352, Train Acc=0.2796 | Test Loss=1.7607, Test Acc=0.2020\n",
      "Epoch 30: Train Loss=1.7360, Train Acc=0.2669 | Test Loss=1.7602, Test Acc=0.2024\n",
      "Epoch 31: Train Loss=1.7362, Train Acc=0.2649 | Test Loss=1.7598, Test Acc=0.2032\n",
      "Epoch 32: Train Loss=1.7336, Train Acc=0.2639 | Test Loss=1.7594, Test Acc=0.2001\n",
      "Epoch 33: Train Loss=1.7317, Train Acc=0.2678 | Test Loss=1.7591, Test Acc=0.2013\n",
      "Epoch 34: Train Loss=1.7280, Train Acc=0.2825 | Test Loss=1.7588, Test Acc=0.2005\n",
      "Epoch 35: Train Loss=1.7317, Train Acc=0.2893 | Test Loss=1.7585, Test Acc=0.2005\n",
      "Epoch 36: Train Loss=1.7292, Train Acc=0.2825 | Test Loss=1.7582, Test Acc=0.2020\n",
      "Epoch 37: Train Loss=1.7247, Train Acc=0.3001 | Test Loss=1.7580, Test Acc=0.2024\n",
      "Epoch 38: Train Loss=1.7249, Train Acc=0.2796 | Test Loss=1.7578, Test Acc=0.2032\n",
      "Epoch 39: Train Loss=1.7226, Train Acc=0.2933 | Test Loss=1.7576, Test Acc=0.2028\n",
      "Epoch 40: Train Loss=1.7201, Train Acc=0.2952 | Test Loss=1.7574, Test Acc=0.2040\n",
      "Epoch 41: Train Loss=1.7195, Train Acc=0.2962 | Test Loss=1.7573, Test Acc=0.2052\n",
      "Epoch 42: Train Loss=1.7174, Train Acc=0.2864 | Test Loss=1.7571, Test Acc=0.2052\n",
      "Epoch 43: Train Loss=1.7089, Train Acc=0.2923 | Test Loss=1.7570, Test Acc=0.2063\n",
      "Epoch 44: Train Loss=1.7094, Train Acc=0.2805 | Test Loss=1.7568, Test Acc=0.2079\n",
      "Epoch 45: Train Loss=1.7032, Train Acc=0.3001 | Test Loss=1.7567, Test Acc=0.2091\n",
      "Epoch 46: Train Loss=1.7059, Train Acc=0.3069 | Test Loss=1.7566, Test Acc=0.2102\n",
      "Epoch 47: Train Loss=1.7094, Train Acc=0.3011 | Test Loss=1.7565, Test Acc=0.2102\n",
      "Epoch 48: Train Loss=1.7009, Train Acc=0.3109 | Test Loss=1.7564, Test Acc=0.2126\n",
      "Epoch 49: Train Loss=1.7023, Train Acc=0.2825 | Test Loss=1.7563, Test Acc=0.2118\n",
      "Epoch 50: Train Loss=1.6975, Train Acc=0.3001 | Test Loss=1.7562, Test Acc=0.2122\n",
      "Epoch 51: Train Loss=1.6971, Train Acc=0.3284 | Test Loss=1.7561, Test Acc=0.2118\n",
      "Epoch 52: Train Loss=1.6897, Train Acc=0.3079 | Test Loss=1.7561, Test Acc=0.2102\n",
      "Epoch 53: Train Loss=1.6832, Train Acc=0.3060 | Test Loss=1.7560, Test Acc=0.2106\n",
      "Epoch 54: Train Loss=1.6877, Train Acc=0.3324 | Test Loss=1.7560, Test Acc=0.2106\n",
      "Epoch 55: Train Loss=1.6886, Train Acc=0.3060 | Test Loss=1.7560, Test Acc=0.2118\n",
      "Epoch 56: Train Loss=1.6814, Train Acc=0.3421 | Test Loss=1.7560, Test Acc=0.2118\n",
      "Epoch 57: Train Loss=1.6761, Train Acc=0.3187 | Test Loss=1.7560, Test Acc=0.2126\n",
      "Epoch 58: Train Loss=1.6737, Train Acc=0.3265 | Test Loss=1.7561, Test Acc=0.2138\n",
      "Epoch 59: Train Loss=1.6721, Train Acc=0.3314 | Test Loss=1.7562, Test Acc=0.2130\n",
      "Epoch 60: Train Loss=1.6681, Train Acc=0.3412 | Test Loss=1.7563, Test Acc=0.2138\n",
      "Epoch 61: Train Loss=1.6656, Train Acc=0.3372 | Test Loss=1.7564, Test Acc=0.2134\n",
      "Epoch 62: Train Loss=1.6568, Train Acc=0.3451 | Test Loss=1.7566, Test Acc=0.2122\n",
      "Epoch 63: Train Loss=1.6541, Train Acc=0.3382 | Test Loss=1.7568, Test Acc=0.2118\n",
      "Epoch 64: Train Loss=1.6535, Train Acc=0.3587 | Test Loss=1.7570, Test Acc=0.2126\n",
      "Epoch 65: Train Loss=1.6453, Train Acc=0.3431 | Test Loss=1.7573, Test Acc=0.2118\n",
      "Epoch 66: Train Loss=1.6433, Train Acc=0.3715 | Test Loss=1.7576, Test Acc=0.2126\n",
      "Epoch 67: Train Loss=1.6369, Train Acc=0.3578 | Test Loss=1.7580, Test Acc=0.2134\n",
      "Epoch 68: Train Loss=1.6308, Train Acc=0.3734 | Test Loss=1.7584, Test Acc=0.2130\n",
      "Epoch 69: Train Loss=1.6398, Train Acc=0.3558 | Test Loss=1.7588, Test Acc=0.2130\n",
      "Epoch 70: Train Loss=1.6220, Train Acc=0.3685 | Test Loss=1.7594, Test Acc=0.2130\n",
      "Epoch 71: Train Loss=1.6153, Train Acc=0.3842 | Test Loss=1.7599, Test Acc=0.2153\n",
      "Epoch 72: Train Loss=1.6157, Train Acc=0.3636 | Test Loss=1.7606, Test Acc=0.2169\n",
      "Epoch 73: Train Loss=1.6195, Train Acc=0.3558 | Test Loss=1.7613, Test Acc=0.2177\n",
      "Epoch 74: Train Loss=1.6058, Train Acc=0.3783 | Test Loss=1.7621, Test Acc=0.2181\n",
      "Epoch 75: Train Loss=1.5985, Train Acc=0.3822 | Test Loss=1.7629, Test Acc=0.2181\n",
      "Epoch 76: Train Loss=1.5949, Train Acc=0.3842 | Test Loss=1.7638, Test Acc=0.2169\n",
      "Epoch 77: Train Loss=1.5846, Train Acc=0.3988 | Test Loss=1.7648, Test Acc=0.2184\n",
      "Epoch 78: Train Loss=1.5872, Train Acc=0.3832 | Test Loss=1.7659, Test Acc=0.2192\n",
      "Epoch 79: Train Loss=1.5837, Train Acc=0.3998 | Test Loss=1.7670, Test Acc=0.2188\n",
      "Epoch 80: Train Loss=1.5793, Train Acc=0.3959 | Test Loss=1.7682, Test Acc=0.2184\n",
      "Epoch 81: Train Loss=1.5685, Train Acc=0.4047 | Test Loss=1.7694, Test Acc=0.2165\n",
      "Epoch 82: Train Loss=1.5585, Train Acc=0.4262 | Test Loss=1.7707, Test Acc=0.2169\n",
      "Epoch 83: Train Loss=1.5569, Train Acc=0.3920 | Test Loss=1.7720, Test Acc=0.2173\n",
      "Epoch 84: Train Loss=1.5485, Train Acc=0.4115 | Test Loss=1.7735, Test Acc=0.2165\n",
      "Epoch 85: Train Loss=1.5331, Train Acc=0.4360 | Test Loss=1.7750, Test Acc=0.2169\n",
      "Epoch 86: Train Loss=1.5441, Train Acc=0.4213 | Test Loss=1.7766, Test Acc=0.2184\n",
      "Epoch 87: Train Loss=1.5244, Train Acc=0.4399 | Test Loss=1.7782, Test Acc=0.2188\n",
      "Epoch 88: Train Loss=1.5194, Train Acc=0.4330 | Test Loss=1.7800, Test Acc=0.2184\n",
      "Epoch 89: Train Loss=1.5185, Train Acc=0.4360 | Test Loss=1.7818, Test Acc=0.2196\n",
      "Epoch 90: Train Loss=1.5179, Train Acc=0.4223 | Test Loss=1.7837, Test Acc=0.2212\n",
      "Epoch 91: Train Loss=1.5082, Train Acc=0.4360 | Test Loss=1.7856, Test Acc=0.2208\n",
      "Epoch 92: Train Loss=1.5016, Train Acc=0.4467 | Test Loss=1.7876, Test Acc=0.2192\n",
      "Epoch 93: Train Loss=1.4762, Train Acc=0.4516 | Test Loss=1.7896, Test Acc=0.2188\n",
      "Epoch 94: Train Loss=1.4722, Train Acc=0.4565 | Test Loss=1.7916, Test Acc=0.2192\n",
      "Epoch 95: Train Loss=1.4670, Train Acc=0.4555 | Test Loss=1.7938, Test Acc=0.2204\n",
      "Epoch 96: Train Loss=1.4647, Train Acc=0.4702 | Test Loss=1.7962, Test Acc=0.2196\n",
      "Epoch 97: Train Loss=1.4610, Train Acc=0.4575 | Test Loss=1.7988, Test Acc=0.2208\n",
      "Epoch 98: Train Loss=1.4376, Train Acc=0.4888 | Test Loss=1.8015, Test Acc=0.2208\n",
      "Epoch 99: Train Loss=1.4314, Train Acc=0.4614 | Test Loss=1.8043, Test Acc=0.2220\n",
      "Epoch 100: Train Loss=1.4316, Train Acc=0.4702 | Test Loss=1.8074, Test Acc=0.2231\n",
      "分類報告 (Train Subset 10%):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.24      0.08      0.12       421\n",
      "       false       0.24      0.38      0.29       501\n",
      "   half-true       0.22      0.10      0.14       526\n",
      " mostly-true       0.22      0.55      0.31       491\n",
      "  pants-fire       0.00      0.00      0.00       209\n",
      "        true       0.16      0.06      0.09       411\n",
      "\n",
      "    accuracy                           0.22      2559\n",
      "   macro avg       0.18      0.19      0.16      2559\n",
      "weighted avg       0.20      0.22      0.18      2559\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "fractions = [1.0, 0.5, 0.25, 0.1]\n",
    "\n",
    "# 設定超參數\n",
    "embed_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = num_classes\n",
    "dropout = 0.5\n",
    "num_epochs = 100\n",
    "batch_size = max_vocab_size\n",
    "learning_rate = 0.001\n",
    "\n",
    "for frac in fractions:\n",
    "    num_train_samples = int(df_train_full.shape[0] * frac)\n",
    "    df_train_subset = df_train_full.iloc[:num_train_samples].reset_index(drop=True)\n",
    "    \n",
    "    subset_percentage = int(frac * 100)\n",
    "    df_train_subset.to_csv(f'train_subset_{subset_percentage}.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"\\n=== 比例 {frac} (約 {num_train_samples} 筆資料) ===\")\n",
    "    model, epoch_list, train_losses, test_losses, train_accuracies, test_accuracies = \\\n",
    "        train_and_evaluate_model(\n",
    "            df_train_subset, df_test_split,\n",
    "            embed_dim, hidden_dim, output_dim,\n",
    "            dropout, num_epochs, batch_size, learning_rate\n",
    "        )\n",
    "    \n",
    "    # 繪製 Loss 與 Accuracy 圖表\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axs[0].plot(epoch_list, train_losses, label='Train Loss')\n",
    "    axs[0].plot(epoch_list, test_losses, label='Test Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].set_title(f'Loss vs Epoch (Train Subset {subset_percentage}%)')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(epoch_list, train_accuracies, label='Train Accuracy')\n",
    "    axs[1].plot(epoch_list, test_accuracies, label='Test Accuracy')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].set_title(f'Accuracy vs Epoch (Train Subset {subset_percentage}%)')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'training_progress_{subset_percentage}_dnn.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 最終模型在測試集上的分類報告\n",
    "    test_loader = create_dataloader(df_test_split, vocab, max_length, le, batch_size, shuffle=False)\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    print(\"分類報告 (Train Subset {}%):\".format(subset_percentage))\n",
    "    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
