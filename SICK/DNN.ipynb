{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 設定隨機種子與裝置\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"SICK_filtered.tsv\", sep=\"\\t\")\n",
    "print(\"原始資料形狀:\", df.shape)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"entailment_label\"])\n",
    "print(\"訓練集形狀:\", df_train.shape, \"測試集形狀:\", df_test.shape)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# 建立詞彙（以訓練集內所有句子合併計算詞頻）\n",
    "all_texts = df_train[\"sentence_A\"].tolist() + df_train[\"sentence_B\"].tolist()\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for t in all_texts:\n",
    "    counter.update(tokenize(t))\n",
    "    \n",
    "max_vocab_size = 10000\n",
    "# 保留 <PAD> 與 <UNK>\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for word, freq in counter.most_common(max_vocab_size - 2):\n",
    "    vocab[word] = len(vocab)\n",
    "vocab_size = len(vocab)\n",
    "print(\"詞彙大小:\", vocab_size)\n",
    "\n",
    "def text_to_ids(text, vocab, max_length=50):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "    if len(ids) < max_length:\n",
    "        ids = ids + [vocab[\"<PAD>\"]] * (max_length - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_length]\n",
    "    return ids\n",
    "\n",
    "max_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SICKDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_length):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        self.sentences_A = df[\"sentence_A\"].tolist()\n",
    "        self.sentences_B = df[\"sentence_B\"].tolist()\n",
    "        self.labels = df[\"entailment_label\"].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sent_A = self.sentences_A[idx]\n",
    "        sent_B = self.sentences_B[idx]\n",
    "        # 轉換成 token id 列表\n",
    "        ids_A = torch.tensor(text_to_ids(sent_A, self.vocab, self.max_length), dtype=torch.long)\n",
    "        ids_B = torch.tensor(text_to_ids(sent_B, self.vocab, self.max_length), dtype=torch.long)\n",
    "        label = self.labels[idx]\n",
    "        return ids_A, ids_B, label\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train[\"label_enc\"] = le.fit_transform(df_train[\"entailment_label\"])\n",
    "df_test[\"label_enc\"] = le.transform(df_test[\"entailment_label\"])\n",
    "num_classes = len(le.classes_)\n",
    "print(\"標籤類別:\", le.classes_)\n",
    "\n",
    "def create_dataloader(df, vocab, max_length, batch_size, shuffle=True):\n",
    "    dataset = SICKDataset(df, vocab, max_length)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_classes, dropout=0.5):\n",
    "        super(EmbeddingDNNClassifier, self).__init__()\n",
    "        # 分別為 sentence_A 與 sentence_B 建立獨立的 Embedding 層\n",
    "        self.embedding_A = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embedding_B = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        # 全連接層，輸入維度為 embed_dim * 2 (因為分別做平均池化後各得到 embed_dim 維向量)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 2, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, ids_A, ids_B):\n",
    "        # 取得 sentence_A 與 sentence_B 的 Embedding，shape: (batch, seq_length, embed_dim)\n",
    "        emb_A = self.embedding_A(ids_A)\n",
    "        emb_B = self.embedding_B(ids_B)\n",
    "        # 對每個句子做平均池化，得到固定維度向量 (batch, embed_dim)\n",
    "        pooled_A = emb_A.mean(dim=1)\n",
    "        pooled_B = emb_B.mean(dim=1)\n",
    "        # 串接兩個句子的向量（不相加）\n",
    "        features = torch.cat([pooled_A, pooled_B], dim=1)  # shape: (batch, embed_dim*2)\n",
    "        logits = self.fc(features)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, test_loader, num_epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for ids_A, ids_B, labels in train_loader:\n",
    "            # 將文字標籤轉換為 tensor\n",
    "            labels = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "            ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ids_A, ids_B)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * ids_A.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # 測試階段\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for ids_A, ids_B, labels in test_loader:\n",
    "                labels = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "                ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "                outputs = model(ids_A, ids_B)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item() * ids_A.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                test_correct += (preds == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "        \n",
    "        test_loss = test_running_loss / test_total\n",
    "        test_acc = test_correct / test_total\n",
    "        \n",
    "        epoch_list.append(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f} | Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    \n",
    "    return epoch_list, train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "X = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料形狀: (9840, 3)\n",
      "訓練集形狀: (7872, 3) 測試集形狀: (1968, 3)\n",
      "詞彙大小: 2439\n",
      "標籤類別: ['CONTRADICTION' 'ENTAILMENT' 'NEUTRAL']\n",
      "\n",
      "[比例 100%] 訓練資料筆數: 7872\n",
      "Epoch 1: Train Loss=1.0268, Train Acc=0.5487 | Test Loss=0.9674, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=0.9552, Train Acc=0.5686 | Test Loss=0.9403, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=0.9387, Train Acc=0.5686 | Test Loss=0.9283, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9207, Train Acc=0.5686 | Test Loss=0.9122, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9021, Train Acc=0.5696 | Test Loss=0.8944, Test Acc=0.5696\n",
      "Epoch 6: Train Loss=0.8786, Train Acc=0.5742 | Test Loss=0.8742, Test Acc=0.5732\n",
      "Epoch 7: Train Loss=0.8563, Train Acc=0.5833 | Test Loss=0.8535, Test Acc=0.5793\n",
      "Epoch 8: Train Loss=0.8298, Train Acc=0.5910 | Test Loss=0.8342, Test Acc=0.5930\n",
      "Epoch 9: Train Loss=0.8054, Train Acc=0.6004 | Test Loss=0.8177, Test Acc=0.5955\n",
      "Epoch 10: Train Loss=0.7838, Train Acc=0.6133 | Test Loss=0.8050, Test Acc=0.5981\n",
      "分類報告 (Train Subset 100%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.60      0.47      0.53       285\n",
      "   ENTAILMENT       0.56      0.06      0.10       564\n",
      "      NEUTRAL       0.60      0.90      0.72      1119\n",
      "\n",
      "     accuracy                           0.60      1968\n",
      "    macro avg       0.59      0.48      0.45      1968\n",
      " weighted avg       0.59      0.60      0.52      1968\n",
      "\n",
      "\n",
      "[比例 50%] 訓練資料筆數: 3936\n",
      "Epoch 1: Train Loss=1.0479, Train Acc=0.5704 | Test Loss=1.0161, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=0.9972, Train Acc=0.5704 | Test Loss=0.9713, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=0.9595, Train Acc=0.5704 | Test Loss=0.9450, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9421, Train Acc=0.5704 | Test Loss=0.9365, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9335, Train Acc=0.5704 | Test Loss=0.9315, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9249, Train Acc=0.5704 | Test Loss=0.9247, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9136, Train Acc=0.5704 | Test Loss=0.9170, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9027, Train Acc=0.5709 | Test Loss=0.9087, Test Acc=0.5691\n",
      "Epoch 9: Train Loss=0.8902, Train Acc=0.5727 | Test Loss=0.8998, Test Acc=0.5696\n",
      "Epoch 10: Train Loss=0.8738, Train Acc=0.5767 | Test Loss=0.8902, Test Acc=0.5676\n",
      "分類報告 (Train Subset 50%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.33      0.01      0.01       285\n",
      "   ENTAILMENT       0.33      0.00      0.01       564\n",
      "      NEUTRAL       0.57      0.99      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.41      0.34      0.25      1968\n",
      " weighted avg       0.47      0.57      0.42      1968\n",
      "\n",
      "\n",
      "[比例 25%] 訓練資料筆數: 1968\n",
      "Epoch 1: Train Loss=1.0792, Train Acc=0.5178 | Test Loss=1.0563, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=1.0421, Train Acc=0.5813 | Test Loss=1.0215, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=1.0081, Train Acc=0.5808 | Test Loss=0.9896, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9763, Train Acc=0.5808 | Test Loss=0.9657, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9542, Train Acc=0.5808 | Test Loss=0.9521, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9428, Train Acc=0.5808 | Test Loss=0.9463, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9379, Train Acc=0.5808 | Test Loss=0.9426, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9334, Train Acc=0.5808 | Test Loss=0.9386, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=0.9288, Train Acc=0.5808 | Test Loss=0.9355, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9240, Train Acc=0.5808 | Test Loss=0.9326, Test Acc=0.5686\n",
      "分類報告 (Train Subset 25%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.00      0.00      0.00       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.57      1.00      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.19      0.33      0.24      1968\n",
      " weighted avg       0.32      0.57      0.41      1968\n",
      "\n",
      "\n",
      "[比例 10%] 訓練資料筆數: 787\n",
      "Epoch 1: Train Loss=1.1278, Train Acc=0.1487 | Test Loss=1.1119, Test Acc=0.1448\n",
      "Epoch 2: Train Loss=1.1088, Train Acc=0.1741 | Test Loss=1.0943, Test Acc=0.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=1.0929, Train Acc=0.3863 | Test Loss=1.0778, Test Acc=0.5417\n",
      "Epoch 4: Train Loss=1.0768, Train Acc=0.5235 | Test Loss=1.0617, Test Acc=0.5655\n",
      "Epoch 5: Train Loss=1.0589, Train Acc=0.5464 | Test Loss=1.0456, Test Acc=0.5681\n",
      "Epoch 6: Train Loss=1.0456, Train Acc=0.5578 | Test Loss=1.0293, Test Acc=0.5691\n",
      "Epoch 7: Train Loss=1.0265, Train Acc=0.5591 | Test Loss=1.0133, Test Acc=0.5691\n",
      "Epoch 8: Train Loss=1.0135, Train Acc=0.5616 | Test Loss=0.9979, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=1.0007, Train Acc=0.5616 | Test Loss=0.9839, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9894, Train Acc=0.5616 | Test Loss=0.9718, Test Acc=0.5686\n",
      "分類報告 (Train Subset 10%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.00      0.00      0.00       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.57      1.00      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.19      0.33      0.24      1968\n",
      " weighted avg       0.32      0.57      0.41      1968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "fractions = [1.0, 0.5, 0.25, 0.1]\n",
    "\n",
    "for frac in fractions:\n",
    "    num_samples = int(len(X) * frac)\n",
    "    df_train_subset = X.iloc[:num_samples].reset_index(drop=True)\n",
    "    subset_percentage = int(frac * 100)\n",
    "    #df_train_subset.to_csv(f\"SICK_train_subset_{subset_percentage}.tsv\", sep=\"\\t\", index=False)\n",
    "    \n",
    "    train_loader = create_dataloader(df_train_subset, vocab, max_length, batch_size, shuffle=True)\n",
    "    test_loader = create_dataloader(df_test, vocab, max_length, batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\n[比例 {subset_percentage}%] 訓練資料筆數: {len(df_train_subset)}\")\n",
    "    \n",
    "    model = EmbeddingDNNClassifier(vocab_size, embed_dim=128, num_classes=num_classes, dropout=0.5)\n",
    "    model.to(device)\n",
    "    \n",
    "    epoch_list, train_losses, test_losses, train_accs, test_accs = train_and_evaluate(model, train_loader, test_loader, num_epochs, learning_rate)\n",
    "    \n",
    "    # 畫圖\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].plot(epoch_list, train_losses, label=\"Train Loss\")\n",
    "    axs[0].plot(epoch_list, test_losses, label=\"Test Loss\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].set_title(f\"Loss vs Epoch (Train Subset {subset_percentage}%)\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(epoch_list, train_accs, label=\"Train Acc\")\n",
    "    axs[1].plot(epoch_list, test_accs, label=\"Test Acc\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_title(f\"Accuracy vs Epoch (Train Subset {subset_percentage}%)\")\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"EmbeddingDNN_SICK_{subset_percentage}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for ids_A, ids_B, labels in test_loader:\n",
    "            labels_tensor = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "            ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "            outputs = model(ids_A, ids_B)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_tensor.cpu().numpy())\n",
    "    \n",
    "    print(f\"分類報告 (Train Subset {subset_percentage}%):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
