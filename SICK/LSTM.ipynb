{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料形狀: (9840, 3)\n",
      "訓練集形狀: (7872, 3) 測試集形狀: (1968, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 讀取 SICK.txt，並只保留 sentence_A, sentence_B, entailment_label\n",
    "df = pd.read_csv(\"SICK.txt\", sep=\"\\t\")\n",
    "df = df[[\"sentence_A\", \"sentence_B\", \"entailment_label\"]]\n",
    "print(\"原始資料形狀:\", df.shape)\n",
    "\n",
    "# 可存檔整理後的資料（選用）\n",
    "#df.to_csv(\"SICK_filtered.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# 切分資料（80% 訓練, 20% 測試），以 entailment_label 做 stratify\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"entailment_label\"])\n",
    "print(\"訓練集形狀:\", df_train.shape, \"測試集形狀:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詞彙大小: 2439\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# 建立詞彙（以訓練集兩個句子合併計算詞頻）\n",
    "all_texts = df_train[\"sentence_A\"].tolist() + df_train[\"sentence_B\"].tolist()\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for t in all_texts:\n",
    "    counter.update(tokenize(t))\n",
    "    \n",
    "max_vocab_size = 10000\n",
    "# 保留 <PAD> 與 <UNK>\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for word, freq in counter.most_common(max_vocab_size - 2):\n",
    "    vocab[word] = len(vocab)\n",
    "vocab_size = len(vocab)\n",
    "print(\"詞彙大小:\", vocab_size)\n",
    "\n",
    "def text_to_ids(text, vocab, max_length=50):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "    if len(ids) < max_length:\n",
    "        ids = ids + [vocab[\"<PAD>\"]] * (max_length - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_length]\n",
    "    return ids\n",
    "\n",
    "# 設定最大序列長度\n",
    "max_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標籤類別: ['CONTRADICTION' 'ENTAILMENT' 'NEUTRAL']\n"
     ]
    }
   ],
   "source": [
    "class SICKDataset(Dataset):\n",
    "    def __init__(self, df, vocab, max_length):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "        self.sentences_A = df[\"sentence_A\"].tolist()\n",
    "        self.sentences_B = df[\"sentence_B\"].tolist()\n",
    "        self.labels = df[\"entailment_label\"].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sent_A = self.sentences_A[idx]\n",
    "        sent_B = self.sentences_B[idx]\n",
    "        # 轉換成 token id 列表\n",
    "        ids_A = torch.tensor(text_to_ids(sent_A, self.vocab, self.max_length), dtype=torch.long)\n",
    "        ids_B = torch.tensor(text_to_ids(sent_B, self.vocab, self.max_length), dtype=torch.long)\n",
    "        label = self.labels[idx]\n",
    "        return ids_A, ids_B, label\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_train[\"label_enc\"] = le.fit_transform(df_train[\"entailment_label\"])\n",
    "df_test[\"label_enc\"] = le.transform(df_test[\"entailment_label\"])\n",
    "num_classes = len(le.classes_)\n",
    "print(\"標籤類別:\", le.classes_)\n",
    "\n",
    "\n",
    "def create_dataloader(df, vocab, max_length, batch_size, shuffle=True):\n",
    "    dataset = SICKDataset(df, vocab, max_length)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, max_length, dropout=0.5):\n",
    "        super(EmbeddingLSTMClassifier, self).__init__()\n",
    "        # 分別為 sentence_A 與 sentence_B 建立獨立的 Embedding 與 LSTM encoder\n",
    "        self.embedding_A = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm_A = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.embedding_B = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm_B = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # 全連接層：將兩個 LSTM 的最後隱藏狀態串接後輸入\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, ids_A, ids_B):\n",
    "        # sentence_A branch\n",
    "        emb_A = self.embedding_A(ids_A)  # shape: (batch, max_length, embed_dim)\n",
    "        out_A, (h_A, _) = self.lstm_A(emb_A)  # h_A shape: (num_layers, batch, hidden_dim)\n",
    "        # 取最末層隱藏狀態\n",
    "        h_A = h_A[-1]  # shape: (batch, hidden_dim)\n",
    "        \n",
    "        # sentence_B branch\n",
    "        emb_B = self.embedding_B(ids_B)  # shape: (batch, max_length, embed_dim)\n",
    "        out_B, (h_B, _) = self.lstm_B(emb_B)\n",
    "        h_B = h_B[-1]  # shape: (batch, hidden_dim)\n",
    "        \n",
    "        # 串接兩邊的向量（不相加）\n",
    "        features = torch.cat([h_A, h_B], dim=1)  # shape: (batch, hidden_dim*2)\n",
    "        \n",
    "        logits = self.fc(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, num_epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for ids_A, ids_B, labels in train_loader:\n",
    "            # 轉換標籤為 tensor\n",
    "            labels = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "            ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(ids_A, ids_B)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * ids_A.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # 測試階段\n",
    "        model.eval()\n",
    "        test_running_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for ids_A, ids_B, labels in test_loader:\n",
    "                labels = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "                ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "                outputs = model(ids_A, ids_B)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_running_loss += loss.item() * ids_A.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                test_correct += (preds == labels).sum().item()\n",
    "                test_total += labels.size(0)\n",
    "        \n",
    "        test_loss = test_running_loss / test_total\n",
    "        test_acc = test_correct / test_total\n",
    "        \n",
    "        epoch_list.append(epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f} | Test Loss={test_loss:.4f}, Test Acc={test_acc:.4f}\")\n",
    "    \n",
    "    return epoch_list, train_losses, test_losses, train_accuracies, test_accuracies\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001\n",
    "\n",
    "X = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[比例 100%] 訓練資料筆數: 7872\n",
      "Epoch 1: Train Loss=0.9955, Train Acc=0.5683 | Test Loss=0.9603, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=0.9654, Train Acc=0.5686 | Test Loss=0.9588, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=0.9619, Train Acc=0.5686 | Test Loss=0.9556, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9495, Train Acc=0.5686 | Test Loss=0.9367, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9350, Train Acc=0.5686 | Test Loss=0.9407, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9269, Train Acc=0.5686 | Test Loss=0.9284, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9200, Train Acc=0.5686 | Test Loss=0.9218, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9205, Train Acc=0.5686 | Test Loss=0.9150, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=0.9163, Train Acc=0.5687 | Test Loss=0.9199, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9122, Train Acc=0.5722 | Test Loss=0.9094, Test Acc=0.5681\n",
      "Epoch 11: Train Loss=0.9067, Train Acc=0.5804 | Test Loss=0.8971, Test Acc=0.5833\n",
      "Epoch 12: Train Loss=0.8990, Train Acc=0.5854 | Test Loss=0.8820, Test Acc=0.5864\n",
      "Epoch 13: Train Loss=0.8925, Train Acc=0.5873 | Test Loss=0.8803, Test Acc=0.5849\n",
      "Epoch 14: Train Loss=0.8913, Train Acc=0.5874 | Test Loss=0.8782, Test Acc=0.5859\n",
      "Epoch 15: Train Loss=0.8871, Train Acc=0.5888 | Test Loss=0.8757, Test Acc=0.5843\n",
      "Epoch 16: Train Loss=0.8778, Train Acc=0.5894 | Test Loss=0.8752, Test Acc=0.5849\n",
      "Epoch 17: Train Loss=0.8720, Train Acc=0.5901 | Test Loss=0.8775, Test Acc=0.5859\n",
      "Epoch 18: Train Loss=0.8710, Train Acc=0.5906 | Test Loss=0.8734, Test Acc=0.5859\n",
      "Epoch 19: Train Loss=0.8696, Train Acc=0.5901 | Test Loss=0.8731, Test Acc=0.5864\n",
      "Epoch 20: Train Loss=0.8635, Train Acc=0.5894 | Test Loss=0.8752, Test Acc=0.5859\n",
      "分類報告 (Train Subset 100%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.57      0.46      0.51       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.59      0.91      0.72      1119\n",
      "\n",
      "     accuracy                           0.59      1968\n",
      "    macro avg       0.39      0.46      0.41      1968\n",
      " weighted avg       0.42      0.59      0.48      1968\n",
      "\n",
      "\n",
      "[比例 50%] 訓練資料筆數: 3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.0223, Train Acc=0.5650 | Test Loss=0.9594, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=0.9608, Train Acc=0.5704 | Test Loss=0.9590, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=0.9605, Train Acc=0.5704 | Test Loss=0.9596, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9633, Train Acc=0.5704 | Test Loss=0.9596, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9592, Train Acc=0.5704 | Test Loss=0.9623, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9525, Train Acc=0.5704 | Test Loss=0.9502, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9439, Train Acc=0.5704 | Test Loss=0.9680, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9403, Train Acc=0.5704 | Test Loss=0.9548, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=0.9292, Train Acc=0.5704 | Test Loss=0.9521, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9248, Train Acc=0.5704 | Test Loss=0.9582, Test Acc=0.5686\n",
      "Epoch 11: Train Loss=0.9173, Train Acc=0.5704 | Test Loss=0.9552, Test Acc=0.5686\n",
      "Epoch 12: Train Loss=0.9177, Train Acc=0.5704 | Test Loss=0.9622, Test Acc=0.5686\n",
      "Epoch 13: Train Loss=0.9145, Train Acc=0.5704 | Test Loss=0.9620, Test Acc=0.5686\n",
      "Epoch 14: Train Loss=0.9032, Train Acc=0.5704 | Test Loss=0.9599, Test Acc=0.5686\n",
      "Epoch 15: Train Loss=0.9026, Train Acc=0.5704 | Test Loss=0.9628, Test Acc=0.5686\n",
      "Epoch 16: Train Loss=0.8940, Train Acc=0.5704 | Test Loss=0.9659, Test Acc=0.5686\n",
      "Epoch 17: Train Loss=0.8971, Train Acc=0.5704 | Test Loss=0.9697, Test Acc=0.5686\n",
      "Epoch 18: Train Loss=0.8890, Train Acc=0.5704 | Test Loss=0.9758, Test Acc=0.5686\n",
      "Epoch 19: Train Loss=0.8858, Train Acc=0.5704 | Test Loss=0.9892, Test Acc=0.5686\n",
      "Epoch 20: Train Loss=0.8805, Train Acc=0.5704 | Test Loss=0.9830, Test Acc=0.5686\n",
      "分類報告 (Train Subset 50%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.00      0.00      0.00       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.57      1.00      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.19      0.33      0.24      1968\n",
      " weighted avg       0.32      0.57      0.41      1968\n",
      "\n",
      "\n",
      "[比例 25%] 訓練資料筆數: 1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=1.0932, Train Acc=0.3877 | Test Loss=1.0623, Test Acc=0.5686\n",
      "Epoch 2: Train Loss=0.9998, Train Acc=0.5788 | Test Loss=0.9638, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=0.9605, Train Acc=0.5808 | Test Loss=0.9644, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=0.9560, Train Acc=0.5808 | Test Loss=0.9591, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9518, Train Acc=0.5803 | Test Loss=0.9585, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9543, Train Acc=0.5808 | Test Loss=0.9595, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9555, Train Acc=0.5808 | Test Loss=0.9549, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9492, Train Acc=0.5808 | Test Loss=0.9536, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=0.9357, Train Acc=0.5803 | Test Loss=0.9527, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9239, Train Acc=0.5808 | Test Loss=0.9589, Test Acc=0.5686\n",
      "Epoch 11: Train Loss=0.9289, Train Acc=0.5803 | Test Loss=0.9593, Test Acc=0.5686\n",
      "Epoch 12: Train Loss=0.9104, Train Acc=0.5803 | Test Loss=0.9593, Test Acc=0.5686\n",
      "Epoch 13: Train Loss=0.9034, Train Acc=0.5808 | Test Loss=0.9634, Test Acc=0.5686\n",
      "Epoch 14: Train Loss=0.8954, Train Acc=0.5808 | Test Loss=0.9792, Test Acc=0.5686\n",
      "Epoch 15: Train Loss=0.8881, Train Acc=0.5808 | Test Loss=0.9704, Test Acc=0.5686\n",
      "Epoch 16: Train Loss=0.8743, Train Acc=0.5803 | Test Loss=0.9769, Test Acc=0.5686\n",
      "Epoch 17: Train Loss=0.8786, Train Acc=0.5808 | Test Loss=0.9759, Test Acc=0.5686\n",
      "Epoch 18: Train Loss=0.8706, Train Acc=0.5808 | Test Loss=0.9965, Test Acc=0.5686\n",
      "Epoch 19: Train Loss=0.8650, Train Acc=0.5803 | Test Loss=0.9812, Test Acc=0.5686\n",
      "Epoch 20: Train Loss=0.8526, Train Acc=0.5808 | Test Loss=0.9895, Test Acc=0.5686\n",
      "分類報告 (Train Subset 25%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.00      0.00      0.00       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.57      1.00      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.19      0.33      0.24      1968\n",
      " weighted avg       0.32      0.57      0.41      1968\n",
      "\n",
      "\n",
      "[比例 10%] 訓練資料筆數: 787\n",
      "Epoch 1: Train Loss=1.1016, Train Acc=0.2884 | Test Loss=1.0881, Test Acc=0.2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=1.0792, Train Acc=0.4587 | Test Loss=1.0636, Test Acc=0.5686\n",
      "Epoch 3: Train Loss=1.0497, Train Acc=0.5515 | Test Loss=1.0286, Test Acc=0.5686\n",
      "Epoch 4: Train Loss=1.0030, Train Acc=0.5616 | Test Loss=0.9613, Test Acc=0.5686\n",
      "Epoch 5: Train Loss=0.9782, Train Acc=0.5616 | Test Loss=0.9602, Test Acc=0.5686\n",
      "Epoch 6: Train Loss=0.9778, Train Acc=0.5616 | Test Loss=0.9650, Test Acc=0.5686\n",
      "Epoch 7: Train Loss=0.9772, Train Acc=0.5616 | Test Loss=0.9599, Test Acc=0.5686\n",
      "Epoch 8: Train Loss=0.9707, Train Acc=0.5616 | Test Loss=0.9595, Test Acc=0.5686\n",
      "Epoch 9: Train Loss=0.9767, Train Acc=0.5616 | Test Loss=0.9601, Test Acc=0.5686\n",
      "Epoch 10: Train Loss=0.9711, Train Acc=0.5616 | Test Loss=0.9602, Test Acc=0.5686\n",
      "Epoch 11: Train Loss=0.9768, Train Acc=0.5616 | Test Loss=0.9616, Test Acc=0.5686\n",
      "Epoch 12: Train Loss=0.9716, Train Acc=0.5616 | Test Loss=0.9597, Test Acc=0.5686\n",
      "Epoch 13: Train Loss=0.9689, Train Acc=0.5616 | Test Loss=0.9586, Test Acc=0.5686\n",
      "Epoch 14: Train Loss=0.9703, Train Acc=0.5616 | Test Loss=0.9586, Test Acc=0.5686\n",
      "Epoch 15: Train Loss=0.9713, Train Acc=0.5616 | Test Loss=0.9586, Test Acc=0.5686\n",
      "Epoch 16: Train Loss=0.9657, Train Acc=0.5616 | Test Loss=0.9603, Test Acc=0.5686\n",
      "Epoch 17: Train Loss=0.9520, Train Acc=0.5616 | Test Loss=0.9587, Test Acc=0.5686\n",
      "Epoch 18: Train Loss=0.9342, Train Acc=0.5616 | Test Loss=0.9654, Test Acc=0.5686\n",
      "Epoch 19: Train Loss=0.9135, Train Acc=0.5616 | Test Loss=0.9886, Test Acc=0.5686\n",
      "Epoch 20: Train Loss=0.8985, Train Acc=0.5616 | Test Loss=0.9783, Test Acc=0.5686\n",
      "分類報告 (Train Subset 10%):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "CONTRADICTION       0.00      0.00      0.00       285\n",
      "   ENTAILMENT       0.00      0.00      0.00       564\n",
      "      NEUTRAL       0.57      1.00      0.72      1119\n",
      "\n",
      "     accuracy                           0.57      1968\n",
      "    macro avg       0.19      0.33      0.24      1968\n",
      " weighted avg       0.32      0.57      0.41      1968\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "fractions = [1.0, 0.5, 0.25, 0.1]\n",
    "\n",
    "for frac in fractions:\n",
    "    num_samples = int(len(X) * frac)\n",
    "    df_train_subset = X.iloc[:num_samples].reset_index(drop=True)\n",
    "    subset_percentage = int(frac*100)\n",
    "    \n",
    "    train_loader = create_dataloader(df_train_subset, vocab, max_length, batch_size, shuffle=True)\n",
    "    test_loader = create_dataloader(df_test, vocab, max_length, batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"\\n[比例 {subset_percentage}%] 訓練資料筆數: {len(df_train_subset)}\")\n",
    "    \n",
    "    model = EmbeddingLSTMClassifier(vocab_size, embed_dim=128, hidden_dim=128, num_classes=num_classes, max_length=max_length, dropout=0.5)\n",
    "    model.to(device)\n",
    "    \n",
    "    epoch_list, train_losses, test_losses, train_accs, test_accs = train_and_evaluate(model, train_loader, test_loader, num_epochs, learning_rate)\n",
    "    \n",
    "    # 畫圖\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "    axs[0].plot(epoch_list, train_losses, label=\"Train Loss\")\n",
    "    axs[0].plot(epoch_list, test_losses, label=\"Test Loss\")\n",
    "    axs[0].set_xlabel(\"Epoch\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].set_title(f\"Loss vs Epoch (Train Subset {subset_percentage}%)\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(epoch_list, train_accs, label=\"Train Acc\")\n",
    "    axs[1].plot(epoch_list, test_accs, label=\"Test Acc\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_title(f\"Accuracy vs Epoch (Train Subset {subset_percentage}%)\")\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"EmbeddingLSTM_SICK_{subset_percentage}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 使用測試集評估最終模型並印出分類報告\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for ids_A, ids_B, labels in test_loader:\n",
    "            labels_tensor = torch.tensor(le.transform(labels), dtype=torch.long).to(device)\n",
    "            ids_A, ids_B = ids_A.to(device), ids_B.to(device)\n",
    "            outputs = model(ids_A, ids_B)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_tensor.cpu().numpy())\n",
    "    \n",
    "    print(f\"分類報告 (Train Subset {subset_percentage}%):\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment_label\n",
      "NEUTRAL          4476\n",
      "ENTAILMENT       2257\n",
      "CONTRADICTION    1139\n",
      "Name: count, dtype: int64\n",
      "entailment_label\n",
      "NEUTRAL          1119\n",
      "ENTAILMENT        564\n",
      "CONTRADICTION     285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"entailment_label\"].value_counts())\n",
    "print(df_test[\"entailment_label\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
