{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合併後資料形狀: (12791, 14)\n",
      "篩選後資料形狀: (7187, 14)\n",
      "完整訓練集形狀: (5749, 14)\n",
      "測試集形狀: (1438, 14)\n",
      "\n",
      "[比例 1.0] 訓練資料筆數: 5749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.38      0.42       501\n",
      "           1       0.39      0.77      0.52       526\n",
      "           2       1.00      0.00      0.00       411\n",
      "\n",
      "    accuracy                           0.41      1438\n",
      "   macro avg       0.62      0.38      0.31      1438\n",
      "weighted avg       0.59      0.41      0.34      1438\n",
      "\n",
      "\n",
      "[比例 0.5] 訓練資料筆數: 2874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.22      0.30       501\n",
      "           1       0.39      0.89      0.54       526\n",
      "           2       0.00      0.00      0.00       411\n",
      "\n",
      "    accuracy                           0.40      1438\n",
      "   macro avg       0.29      0.37      0.28      1438\n",
      "weighted avg       0.31      0.40      0.30      1438\n",
      "\n",
      "\n",
      "[比例 0.25] 訓練資料筆數: 1437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.27      0.33       501\n",
      "           1       0.38      0.81      0.52       526\n",
      "           2       0.36      0.01      0.02       411\n",
      "\n",
      "    accuracy                           0.39      1438\n",
      "   macro avg       0.39      0.36      0.29      1438\n",
      "weighted avg       0.39      0.39      0.31      1438\n",
      "\n",
      "\n",
      "[比例 0.1] 訓練資料筆數: 574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.34      0.36       501\n",
      "           1       0.38      0.68      0.49       526\n",
      "           2       0.37      0.08      0.14       411\n",
      "\n",
      "    accuracy                           0.39      1438\n",
      "   macro avg       0.39      0.36      0.33      1438\n",
      "weighted avg       0.39      0.39      0.35      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "columns = ['id', 'label', 'statement', 'subjects', 'speaker', 'job_title', 'state', 'party', \n",
    "           'barely_true', 'false', 'half_true', 'mostly_true', 'pants_on_fire', 'context']\n",
    "\n",
    "# 讀取各個 TSV 檔案（注意檔案名稱需與實際檔名相符）\n",
    "df_train = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "df_valid = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "df_test = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "# 合併資料\n",
    "df_total = pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "print(\"合併後資料形狀:\", df_total.shape)\n",
    "\n",
    "# 篩選出 label 為 'true', 'half-true', 'false' 的資料\n",
    "df_total = df_total[df_total['label'].isin(['true', 'half-true', 'false'])]\n",
    "print(\"篩選後資料形狀:\", df_total.shape)\n",
    "\n",
    "# 存檔：合併後的資料存成 data.tsv\n",
    "df_total.to_csv('data.tsv', sep='\\t', index=False)\n",
    "\n",
    "df_train_full, df_test_split = train_test_split(\n",
    "    df_total, test_size=0.2, random_state=42, stratify=df_total['label'])\n",
    "print(\"完整訓練集形狀:\", df_train_full.shape)\n",
    "print(\"測試集形狀:\", df_test_split.shape)\n",
    "\n",
    "# 存檔：訓練與測試集分別存檔\n",
    "df_train_full.to_csv('train_full.tsv', sep='\\t', index=False)\n",
    "df_test_split.to_csv('test_split.tsv', sep='\\t', index=False)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "# 先在完整訓練集上 fit，再轉換訓練與測試集的「statement」欄位\n",
    "X_train_full = vectorizer.fit_transform(df_train_full['statement']).toarray()\n",
    "X_test = vectorizer.transform(df_test_split['statement']).toarray()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_full = le.fit_transform(df_train_full['label'])\n",
    "y_test = le.transform(df_test_split['label'])\n",
    "\n",
    "\n",
    "# 定義要使用的訓練集比例\n",
    "fractions = [1.0, 0.5, 0.25, 0.1]\n",
    "\n",
    "# 設定最終樹的數量與每次新增的樹數（這裡以 1 為單位追蹤變化）\n",
    "final_n_estimators = 200\n",
    "\n",
    "for frac in fractions:\n",
    "    num_train_samples = int(X_train_full.shape[0] * frac)\n",
    "    \n",
    "    # 取出對應比例的子資料集（DataFrame 與特徵、標籤）\n",
    "    df_train_subset = df_train_full.iloc[:num_train_samples]\n",
    "    X_train = X_train_full[:num_train_samples]\n",
    "    y_train = y_train_full[:num_train_samples]\n",
    "    \n",
    "    subset_percentage = int(frac * 100)\n",
    "    df_train_subset.to_csv(f'train_subset_{subset_percentage}.tsv', sep='\\t', index=False)\n",
    "    \n",
    "    print(f\"\\n[比例 {frac}] 訓練資料筆數: {num_train_samples}\")\n",
    "    \n",
    "    # 使用 warm_start 模式建立 RandomForestClassifier\n",
    "    model = RandomForestClassifier(\n",
    "        warm_start=True,    # 啟用 warm_start 以便逐步增加樹的數量\n",
    "        n_estimators=0,     # 從 0 棵樹開始，後續依次累加\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 用來紀錄每個迭代步驟的指標\n",
    "    n_estimators_list = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    # 逐步增加樹的數量，模擬訓練過程\n",
    "    for i in range(1, final_n_estimators + 1):\n",
    "        model.n_estimators = i\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 計算預測機率，用以計算 log loss\n",
    "        y_train_proba = model.predict_proba(X_train)\n",
    "        y_test_proba = model.predict_proba(X_test)\n",
    "        \n",
    "        # 計算 log loss (注意：若某些類別預測機率過低，log_loss 可能會警告)\n",
    "        train_loss = log_loss(y_train, y_train_proba)\n",
    "        test_loss = log_loss(y_test, y_test_proba)\n",
    "        \n",
    "        # 計算 accuracy\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        # 紀錄指標\n",
    "        n_estimators_list.append(i)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "    \n",
    "    # 畫圖：建立一個圖表，左圖為 Loss 變化，右圖為 Accuracy 變化\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    axs[0].plot(n_estimators_list, train_losses, label=\"Train Loss\")\n",
    "    axs[0].plot(n_estimators_list, test_losses, label=\"Test Loss\")\n",
    "    axs[0].set_xlabel(\"Number of Trees\")\n",
    "    axs[0].set_ylabel(\"Log Loss\")\n",
    "    axs[0].set_title(f\"Loss vs Trees (Train Subset {subset_percentage}%)\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(n_estimators_list, train_accuracies, label=\"Train Accuracy\")\n",
    "    axs[1].plot(n_estimators_list, test_accuracies, label=\"Test Accuracy\")\n",
    "    axs[1].set_xlabel(\"Number of Trees\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].set_title(f\"Accuracy vs Trees (Train Subset {subset_percentage}%)\")\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # 存檔圖表\n",
    "    plt.savefig(f'RF_{subset_percentage}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 另外也印出最終模型的分類報告\n",
    "    final_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, final_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合併後資料形狀: (12791, 14)\n",
      "篩選後資料形狀: (7187, 14)\n",
      "完整訓練集形狀: (5749, 14)\n",
      "測試集形狀: (1438, 14)\n",
      "Classifier A (true vs not true):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not true       0.71      1.00      0.83      1027\n",
      "        true       0.00      0.00      0.00       411\n",
      "\n",
      "    accuracy                           0.71      1438\n",
      "   macro avg       0.36      0.50      0.42      1438\n",
      "weighted avg       0.51      0.71      0.60      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier B (half-true vs false):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.62      0.45      0.52       501\n",
      "   half-true       0.58      0.73      0.65       526\n",
      "\n",
      "    accuracy                           0.59      1027\n",
      "   macro avg       0.60      0.59      0.59      1027\n",
      "weighted avg       0.60      0.59      0.59      1027\n",
      "\n",
      "最終組合分類器效能:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.45      0.45      0.45       501\n",
      "   half-true       0.41      0.73      0.53       526\n",
      "        true       0.00      0.00      0.00       411\n",
      "\n",
      "    accuracy                           0.42      1438\n",
      "   macro avg       0.29      0.39      0.33      1438\n",
      "weighted avg       0.31      0.42      0.35      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kenny1208/anaconda3/envs/Torch/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 設定隨機種子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 定義欄位名稱（依 LIAR 資料集格式）\n",
    "columns = ['id', 'label', 'statement', 'subjects', 'speaker', 'job_title', 'state', 'party', \n",
    "           'barely_true', 'false', 'half_true', 'mostly_true', 'pants_on_fire', 'context']\n",
    "\n",
    "# 讀取三個 TSV 資料集\n",
    "df_train = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "df_valid = pd.read_csv('valid.tsv', sep='\\t', header=None, names=columns)\n",
    "df_test = pd.read_csv('test.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "# 合併資料\n",
    "df_total = pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "print(\"合併後資料形狀:\", df_total.shape)\n",
    "\n",
    "# 只保留標籤為 \"true\", \"half-true\", \"false\" 的資料\n",
    "df_total = df_total[df_total['label'].isin(['true', 'half-true', 'false'])]\n",
    "print(\"篩選後資料形狀:\", df_total.shape)\n",
    "\n",
    "# 存檔合併後的資料（data.tsv）\n",
    "#df_total.to_csv('data.tsv', sep='\\t', index=False)\n",
    "\n",
    "# 切分成訓練與測試集（80% / 20%）\n",
    "df_train_full, df_test_split = train_test_split(\n",
    "    df_total, test_size=0.2, random_state=42, stratify=df_total['label'])\n",
    "print(\"完整訓練集形狀:\", df_train_full.shape)\n",
    "print(\"測試集形狀:\", df_test_split.shape)\n",
    "\n",
    "# 存檔訓練與測試集\n",
    "#df_train_full.to_csv('train_full.tsv', sep='\\t', index=False)\n",
    "#df_test_split.to_csv('test_split.tsv', sep='\\t', index=False)\n",
    "\n",
    "# 建立 TF-IDF 向量化器，並轉換文本（以 \"statement\" 欄位為例）\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_full = vectorizer.fit_transform(df_train_full['statement']).toarray()\n",
    "X_test = vectorizer.transform(df_test_split['statement']).toarray()\n",
    "\n",
    "# ----------------------------\n",
    "# 建立 Classifier A: \"true\" vs \"not true\"\n",
    "# ----------------------------\n",
    "# 定義轉換函數：如果原始標籤為 \"true\"，保留；否則轉為 \"not true\"\n",
    "def map_label_A(label):\n",
    "    return 'true' if label == 'true' else 'not true'\n",
    "\n",
    "df_train_full['label_A'] = df_train_full['label'].apply(map_label_A)\n",
    "df_test_split['label_A'] = df_test_split['label'].apply(map_label_A)\n",
    "\n",
    "le_A = LabelEncoder()\n",
    "y_train_A = le_A.fit_transform(df_train_full['label_A'])\n",
    "y_test_A = le_A.transform(df_test_split['label_A'])\n",
    "\n",
    "# ----------------------------\n",
    "# 建立 Classifier B: 區分 \"half-true\" 與 \"false\"\n",
    "# ----------------------------\n",
    "# 只挑出原始標籤不為 \"true\" 的資料來訓練 classifier B\n",
    "df_train_B = df_train_full[df_train_full['label'] != 'true'].reset_index(drop=True)\n",
    "df_test_B = df_test_split[df_test_split['label'] != 'true'].reset_index(drop=True)\n",
    "\n",
    "le_B = LabelEncoder()\n",
    "y_train_B = le_B.fit_transform(df_train_B['label'])\n",
    "y_test_B = le_B.transform(df_test_B['label'])\n",
    "\n",
    "# 分別取得對應的 TF-IDF 特徵 (利用相同 vectorizer)\n",
    "X_train_B = vectorizer.transform(df_train_B['statement']).toarray()\n",
    "X_test_B = vectorizer.transform(df_test_B['statement']).toarray()\n",
    "\n",
    "# ----------------------------\n",
    "# 訓練 Classifier A (區分 \"true\" vs \"not true\")\n",
    "# ----------------------------\n",
    "model_A = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "model_A.fit(X_train_full, y_train_A)\n",
    "pred_A = model_A.predict(X_test)\n",
    "\n",
    "print(\"Classifier A (true vs not true):\")\n",
    "print(classification_report(y_test_A, pred_A, target_names=le_A.classes_))\n",
    "\n",
    "# ----------------------------\n",
    "# 訓練 Classifier B (區分 \"half-true\" vs \"false\")\n",
    "# ----------------------------\n",
    "model_B = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "model_B.fit(X_train_B, y_train_B)\n",
    "pred_B = model_B.predict(X_test_B)\n",
    "\n",
    "print(\"Classifier B (half-true vs false):\")\n",
    "print(classification_report(y_test_B, pred_B, target_names=le_B.classes_))\n",
    "\n",
    "# ----------------------------\n",
    "# 結合兩階段分類器進行最終預測\n",
    "# ----------------------------\n",
    "final_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    # 先用 classifier A 預測\n",
    "    pred_A_label = le_A.inverse_transform([model_A.predict(X_test[i].reshape(1, -1))[0]])[0]\n",
    "    if pred_A_label == 'true':\n",
    "        final_predictions.append('true')\n",
    "    else:\n",
    "        # 若預測為 \"not true\"，則用 classifier B 進行進一步細分\n",
    "        pred_B_label = le_B.inverse_transform([model_B.predict(X_test[i].reshape(1, -1))[0]])[0]\n",
    "        final_predictions.append(pred_B_label)\n",
    "\n",
    "# 評估最終組合後的預測結果（使用原始三分類標籤）\n",
    "print(\"最終組合分類器效能:\")\n",
    "print(classification_report(df_test_split['label'], final_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
